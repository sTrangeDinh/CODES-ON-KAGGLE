{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"},{"sourceId":4958,"sourceType":"datasetVersion","datasetId":2847}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MARKDOWN TECHNIQUES FLOW","metadata":{}},{"cell_type":"code","source":"\"\"\"\nOLD CODE: VER 1\n\"\"\"\n# import os, os.path \n\n# # --- KAGGLE CONFIGURATION ---\n\n# # 1. Define the Base Directory\n# # Kaggle inputs are always read-only and located in /kaggle/input\n# # You usually have a dataset folder name (e.g., 'biomass-data'). \n# # If you don't know the exact folder name yet, you can list directories:\n# # print(os.listdir(\"/kaggle/input\")) \n# BASE_DIR = '/kaggle/input' \n\n# # 2. Define Path to CSV\n# # Update 'your-dataset-name' to the actual folder name in Kaggle\n# CSV_PATH = os.path.join(BASE_DIR, 'your-dataset-name', 'train.csv')\n# TEST_CSV_PATH = os.path.join(BASE_DIR, 'your-dataset-name', 'test.csv')\n\n# # 3. Define Root Directory for Images\n# # Usually images are in a subfolder or directly in the dataset folder\n# IMAGE_ROOT = os.path.join(BASE_DIR, 'your-dataset-name', 'train')\n# TEST_IMAGE_ROOT = os.path.join(BASE_DIR, 'your-dataset-name', 'test')\n\n# # 4. Verification\n# if os.path.exists(CSV_PATH):\n#     print(f\"✅ Found CSV at: {CSV_PATH}\")\n# else:\n#     print(f\"❌ CSV not found at: {CSV_PATH}\")\n#     # Helper to find the real path if the above is wrong\n#     print(\"Available files in input:\", os.listdir(BASE_DIR))\n\n# if os.path.exists(IMAGE_ROOT):\n#     print(f\"✅ Found Image Dir at: {IMAGE_ROOT}\")\n# else:\n#     print(f\"❌ Image Dir not found at: {IMAGE_ROOT}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nOLD CODE: VER 2 FROM GEMINI\n\"\"\"\n\"\"\"\nKaggle to GitHub Sync Configuration\nRepository: CODES-ON-KAGGLE\n\"\"\"\n# from pathlib import Path\n# import os\n\n# # --- KAGGLE CONFIGURATION ---\n\n# # 1. Define the Base Directory using pathlib\n# # Kaggle inputs are read-only and located in /kaggle/input\n# BASE_DIR = Path('/kaggle/input') \n\n# # 2. Define the Dataset Name \n# # Change 'project-name' to the folder name found in /kaggle/input\n# # NOTE: 'project-name' can be found by looking at the URL when accessing Kaggle Competitions\n# DATASET_NAME = 'csiro-biomass'\n# DATASET_PATH = BASE_DIR / DATASET_NAME\n\n# # 3. Define Paths to CSVs and Image Directories\n# # We use the / operator for clean, cross-platform path joining\n# TRAIN_CSV_PATH = DATASET_PATH / 'train.csv'\n# TEST_CSV_PATH = DATASET_PATH / 'test.csv'\n\n# TRAIN_IMAGES_ROOT = DATASET_PATH / 'train'\n# TEST_IMAGE_ROOT = DATASET_PATH / 'test'\n\n# # 4. Verification Logic\n# def verify_paths():\n#     paths_to_check = {\n#         \"Training CSV\": TRAIN_CSV_PATH,\n#         \"Testing CSV\": TEST_CSV_PATH,\n#         \"Train Images Root\": TRAIN_IMAGES_ROOT,\n#         \"Test Image Root\"  : TEST_IMAGE_ROOT\n#     }\n    \n#     print(f\"--- Path Verification for {DATASET_NAME} ---\")\n#     for name, path in paths_to_check.items():\n#         if path.exists():\n#             print(f\"✅ {name} found at: {path}\")\n#         else:\n#             print(f\"❌ {name} NOT found at: {path}\")\n            \n#     # If the main folder isn't found, list what is available\n#     if not DATASET_PATH.exists():\n#         print(f\"\\nAvailable directories in {BASE_DIR}:\")\n#         print([p.name for p in BASE_DIR.iterdir() if p.is_dir()])\n\n# if __name__ == \"__main__\":\n#     verify_paths()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T00:25:19.613799Z","iopub.execute_input":"2026-01-05T00:25:19.614157Z","iopub.status.idle":"2026-01-05T00:25:19.631923Z","shell.execute_reply.started":"2026-01-05T00:25:19.614132Z","shell.execute_reply":"2026-01-05T00:25:19.630965Z"}},"outputs":[{"name":"stdout","text":"--- Path Verification for csiro-biomass ---\n✅ Training CSV found at: /kaggle/input/csiro-biomass/train.csv\n✅ Testing CSV found at: /kaggle/input/csiro-biomass/test.csv\n✅ Train Images Root found at: /kaggle/input/csiro-biomass/train\n✅ Test Image Root found at: /kaggle/input/csiro-biomass/test\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 1. IMPORT LIBARIES + PATHS + REPRODUCBILITY","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 1 — Imports + Paths + Reprocibility\n# ============================================\n\"\"\"\nKaggle to GitHub Sync Configuration\nRepository: CODES-ON-KAGGLE\n\"\"\"\n# Import\nimport os\nimport re\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom PIL import Image\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Reproducibility\ndef set_seed(seed: int = 42) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\n# ✅ Competition directory (as you stated)\nDATA_DIR = \"/kaggle/input/csiro-biomass\"\n\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\nTEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\nSAMPLE_SUB_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n\n# ✅ Pretrained weights dataset input\nWEIGHTS_DIR = \"/kaggle/input/pretrained-pytorch-models\"\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Safety checks (fail fast if something isn't mounted)\nfor p in [DATA_DIR, WEIGHTS_DIR, TRAIN_CSV, TEST_CSV, SAMPLE_SUB_CSV]:\n    if not os.path.exists(p):\n        raise FileNotFoundError(f\"Missing expected path: {p}\")\n\nprint(\"DATA_DIR:\", DATA_DIR)\nprint(\"WEIGHTS_DIR:\", WEIGHTS_DIR)\nprint(\"DEVICE:\", DEVICE)\nprint(\"Train CSV:\", TRAIN_CSV)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. HARDWARE & REPRODUCIBILITY","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef process_test_structure(csv_path):\n    \"\"\"\n    Parses the Kaggle-style test.csv into a format compatible with BiomassDataset.\n    Input: Raw test CSV with 5 rows per image.\n    Output: DataFrame with 1 row per image and 5 dummy target columns.\n    \"\"\"\n    # 1. Read the raw data\n    raw_df = pd.read_csv(csv_path)\n    \n    # 2. Extract unique images\n    # The CSV lists 5 rows for every 1 image (one for each target type).\n    # We slice with a stride of 5 to get unique image entries.\n    df_unique = raw_df.iloc[::5].copy()\n    \n    # 3. initialize the output DataFrame with the filename\n    # We reset the index to ensure it starts from 0 to len(df)-1\n    df_YY_new = df_unique[['image_path']].reset_index(drop=True)\n    \n    # 4. Add dummy target columns\n    # The Dataset class expects columns 1-5 to be float values. \n    # Since this is inference, we fill them with 0.0.\n    # The order MUST match the training set order.\n    target_cols = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n    \n    for col in target_cols:\n        df_YY_new[col] = 0.0\n        \n    return df_YY_new\n\n# Apply the function\ndf_YY = process_test_structure('test.csv')\n\n# Verify the structure\nprint(\"New df_YY shape:\", df_YY.shape)\nprint(df_YY.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. EXTRACT FEATURE FROM THE TRAINED IMAGES","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\n# FIX: Import the functional interface as 'F' so SquarePad can use it\nimport torchvision.transforms.functional as F\n\nclass SquarePad:\n    \"\"\"\n    Pads the image with black pixels to make it square, preserving aspect ratio.\n    \"\"\"\n    def __call__(self, image):\n        w, h = image.size\n        max_wh = max(w, h)\n        p_left = (max_wh - w) // 2\n        p_top  = (max_wh - h) // 2\n        p_right = max_wh - w - p_left\n        p_bottom = max_wh - h - p_top\n        return F.pad(image, (p_left, p_top, p_right, p_bottom), 0, 'constant')\n\ndef get_feature_extractor(device, weight_path='/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth'):\n    \"\"\"\n    Loads ResNet18 weights safely by first mapping them to CPU.\n    \"\"\"\n    # 1. Initialize the model architecture\n    model = models.resnet18(weights=None)\n    \n    # 2. Load the weights from the local file\n    try:\n        # Load to CPU first to avoid device conflicts\n        state_dict = torch.load(weight_path, map_location=\"cpu\", weights_only=False)\n        model.load_state_dict(state_dict)\n        print(f\"✅ Loaded local weights from {weight_path}\")\n    except FileNotFoundError:\n        print(f\"❌ Error: Could not find weights at {weight_path}\")\n        raise\n    except Exception as e:\n        print(f\"❌ Error loading state dict: {e}\")\n        raise\n\n    # 3. Remove classification head\n    modules = list(model.children())[:-1] \n    extractor = nn.Sequential(*modules)\n    \n    # 4. Move to target device\n    extractor.to(device)\n    extractor.eval()\n    \n    # 5. Freeze parameters\n    for param in extractor.parameters():\n        param.requires_grad = False\n        \n    # 6. Define Transforms\n    transform = transforms.Compose([\n        SquarePad(), # Now works because 'F' is defined\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                             std=[0.229, 0.224, 0.225])\n    ])\n\n    return extractor, transform\n# --- 2. Batched Feature Extraction ---\ndef extract_features_batched(df, image_root, batch_size=32, weight_path='/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth'):\n    \"\"\"\n    Extracts features using the locally loaded ResNet18 model.\n    \"\"\"\n    # Pass the specific weight path to the helper function\n    extractor, transform = get_feature_extractor(DEVICE, weight_path=weight_path)\n    \n    # Create Dataset\n    # Ensure your BiomassDataset class is already defined before running this!\n    dataset = BiomassDataset(df, image_root, transform=transform)\n    \n    # DataLoader: num_workers=2 is efficient for Kaggle/Linux\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2) \n    \n    features_list = []\n    \n    print(f\"Extracting features for {len(df)} images (Batch Size: {batch_size})...\")\n    \n    with torch.no_grad():\n        for batch_imgs in tqdm(loader, desc=\"Processing\"):\n            batch_imgs = batch_imgs.to(DEVICE)\n            \n            # Forward Pass\n            preds = extractor(batch_imgs)      # Shape: [Batch, 512, 1, 1]\n            preds = preds.view(preds.size(0), -1) # Flatten: [Batch, 512]\n            \n            features_list.append(preds.cpu().numpy())\n            \n    return np.vstack(features_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}