{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d751c07f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:02.849362Z",
     "iopub.status.busy": "2026-01-05T02:51:02.849043Z",
     "iopub.status.idle": "2026-01-05T02:51:02.853388Z",
     "shell.execute_reply": "2026-01-05T02:51:02.852803Z"
    },
    "papermill": {
     "duration": 0.011744,
     "end_time": "2026-01-05T02:51:02.854972",
     "exception": false,
     "start_time": "2026-01-05T02:51:02.843228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2316011",
   "metadata": {
    "papermill": {
     "duration": 0.003614,
     "end_time": "2026-01-05T02:51:02.862449",
     "exception": false,
     "start_time": "2026-01-05T02:51:02.858835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MARKDOWN TECHNIQUES FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf03cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:02.870641Z",
     "iopub.status.busy": "2026-01-05T02:51:02.870162Z",
     "iopub.status.idle": "2026-01-05T02:51:02.878256Z",
     "shell.execute_reply": "2026-01-05T02:51:02.877581Z"
    },
    "papermill": {
     "duration": 0.013701,
     "end_time": "2026-01-05T02:51:02.879734",
     "exception": false,
     "start_time": "2026-01-05T02:51:02.866033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOLD CODE: VER 1\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "OLD CODE: VER 1\n",
    "\"\"\"\n",
    "# import os, os.path \n",
    "\n",
    "# # --- KAGGLE CONFIGURATION ---\n",
    "\n",
    "# # 1. Define the Base Directory\n",
    "# # Kaggle inputs are always read-only and located in /kaggle/input\n",
    "# # You usually have a dataset folder name (e.g., 'biomass-data'). \n",
    "# # If you don't know the exact folder name yet, you can list directories:\n",
    "# # print(os.listdir(\"/kaggle/input\")) \n",
    "# BASE_DIR = '/kaggle/input' \n",
    "\n",
    "# # 2. Define Path to CSV\n",
    "# # Update 'your-dataset-name' to the actual folder name in Kaggle\n",
    "# CSV_PATH = os.path.join(BASE_DIR, 'your-dataset-name', 'train.csv')\n",
    "# TEST_CSV_PATH = os.path.join(BASE_DIR, 'your-dataset-name', 'test.csv')\n",
    "\n",
    "# # 3. Define Root Directory for Images\n",
    "# # Usually images are in a subfolder or directly in the dataset folder\n",
    "# IMAGE_ROOT = os.path.join(BASE_DIR, 'your-dataset-name', 'train')\n",
    "# TEST_IMAGE_ROOT = os.path.join(BASE_DIR, 'your-dataset-name', 'test')\n",
    "\n",
    "# # 4. Verification\n",
    "# if os.path.exists(CSV_PATH):\n",
    "#     print(f\"✅ Found CSV at: {CSV_PATH}\")\n",
    "# else:\n",
    "#     print(f\"❌ CSV not found at: {CSV_PATH}\")\n",
    "#     # Helper to find the real path if the above is wrong\n",
    "#     print(\"Available files in input:\", os.listdir(BASE_DIR))\n",
    "\n",
    "# if os.path.exists(IMAGE_ROOT):\n",
    "#     print(f\"✅ Found Image Dir at: {IMAGE_ROOT}\")\n",
    "# else:\n",
    "#     print(f\"❌ Image Dir not found at: {IMAGE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a24b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:02.888222Z",
     "iopub.status.busy": "2026-01-05T02:51:02.887584Z",
     "iopub.status.idle": "2026-01-05T02:51:02.893555Z",
     "shell.execute_reply": "2026-01-05T02:51:02.892843Z"
    },
    "papermill": {
     "duration": 0.011983,
     "end_time": "2026-01-05T02:51:02.895024",
     "exception": false,
     "start_time": "2026-01-05T02:51:02.883041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nKaggle to GitHub Sync Configuration\\nRepository: CODES-ON-KAGGLE\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "OLD CODE: VER 2 FROM GEMINI\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Kaggle to GitHub Sync Configuration\n",
    "Repository: CODES-ON-KAGGLE\n",
    "\"\"\"\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "\n",
    "# # --- KAGGLE CONFIGURATION ---\n",
    "\n",
    "# # 1. Define the Base Directory using pathlib\n",
    "# # Kaggle inputs are read-only and located in /kaggle/input\n",
    "# BASE_DIR = Path('/kaggle/input') \n",
    "\n",
    "# # 2. Define the Dataset Name \n",
    "# # Change 'project-name' to the folder name found in /kaggle/input\n",
    "# # NOTE: 'project-name' can be found by looking at the URL when accessing Kaggle Competitions\n",
    "# DATASET_NAME = 'csiro-biomass'\n",
    "# DATASET_PATH = BASE_DIR / DATASET_NAME\n",
    "\n",
    "# # 3. Define Paths to CSVs and Image Directories\n",
    "# # We use the / operator for clean, cross-platform path joining\n",
    "# TRAIN_CSV_PATH = DATASET_PATH / 'train.csv'\n",
    "# TEST_CSV_PATH = DATASET_PATH / 'test.csv'\n",
    "\n",
    "# TRAIN_IMAGES_ROOT = DATASET_PATH / 'train'\n",
    "# TEST_IMAGE_ROOT = DATASET_PATH / 'test'\n",
    "\n",
    "# # 4. Verification Logic\n",
    "# def verify_paths():\n",
    "#     paths_to_check = {\n",
    "#         \"Training CSV\": TRAIN_CSV_PATH,\n",
    "#         \"Testing CSV\": TEST_CSV_PATH,\n",
    "#         \"Train Images Root\": TRAIN_IMAGES_ROOT,\n",
    "#         \"Test Image Root\"  : TEST_IMAGE_ROOT\n",
    "#     }\n",
    "    \n",
    "#     print(f\"--- Path Verification for {DATASET_NAME} ---\")\n",
    "#     for name, path in paths_to_check.items():\n",
    "#         if path.exists():\n",
    "#             print(f\"✅ {name} found at: {path}\")\n",
    "#         else:\n",
    "#             print(f\"❌ {name} NOT found at: {path}\")\n",
    "            \n",
    "#     # If the main folder isn't found, list what is available\n",
    "#     if not DATASET_PATH.exists():\n",
    "#         print(f\"\\nAvailable directories in {BASE_DIR}:\")\n",
    "#         print([p.name for p in BASE_DIR.iterdir() if p.is_dir()])\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     verify_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c3449",
   "metadata": {
    "papermill": {
     "duration": 0.00358,
     "end_time": "2026-01-05T02:51:02.902421",
     "exception": false,
     "start_time": "2026-01-05T02:51:02.898841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. IMPORT LIBARIES + PATHS + REPRODUCBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b4bd5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:02.910221Z",
     "iopub.status.busy": "2026-01-05T02:51:02.909993Z",
     "iopub.status.idle": "2026-01-05T02:51:14.338517Z",
     "shell.execute_reply": "2026-01-05T02:51:14.337640Z"
    },
    "papermill": {
     "duration": 11.434398,
     "end_time": "2026-01-05T02:51:14.340159",
     "exception": false,
     "start_time": "2026-01-05T02:51:02.905761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DATA_DIR: /kaggle/input/csiro-biomass\n",
      "✅ WEIGHTS_DIR: /kaggle/input/pretrained-pytorch-models\n",
      "✅ DEVICE: cuda\n",
      "✅ Train CSV: /kaggle/input/csiro-biomass/train.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1 — Imports + Paths + Reprocibility\n",
    "# ============================================\n",
    "\"\"\"\n",
    "Kaggle to GitHub Sync Configuration\n",
    "Repository: CODES-ON-KAGGLE\n",
    "\"\"\"\n",
    "# Import\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ✅ Competition directory (as you stated)\n",
    "DATA_DIR = \"/kaggle/input/csiro-biomass\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "SAMPLE_SUB_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# ✅ Pretrained weights dataset input for model resnet18\n",
    "WEIGHTS_DIR = \"/kaggle/input/pretrained-pytorch-models\"\n",
    "\n",
    "# Inference\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# BATCH_SIZE = 1 # INCREASE BATCH SIZE WHEN INFERENCE\n",
    "# NUM_WORKERS = 1 # 2 IN MY PRIOR DELETED VERSION\n",
    "# N_FOLDS = 5 \n",
    "\n",
    "# Safety checks (fail fast if something isn't mounted)\n",
    "for p in [DATA_DIR, WEIGHTS_DIR, TRAIN_CSV, TEST_CSV, SAMPLE_SUB_CSV]:\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Missing expected path: {p}\")\n",
    "\n",
    "print(\"✅ DATA_DIR:\", DATA_DIR)\n",
    "print(\"✅ WEIGHTS_DIR:\", WEIGHTS_DIR)\n",
    "print(\"✅ DEVICE:\", DEVICE)\n",
    "print(\"✅ Train CSV:\", TRAIN_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cfebf",
   "metadata": {
    "papermill": {
     "duration": 0.003329,
     "end_time": "2026-01-05T02:51:14.347000",
     "exception": false,
     "start_time": "2026-01-05T02:51:14.343671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. SETUP WEIGHTS FOR THE OFFLINE RESNET 18\n",
    "Since we run code when the Internet is off, we have to manually input a dataset on Kaggle\n",
    "that contains ResNet18 ImageNet weights.\n",
    "The ResNet18 ImageNet weights will be named resnet18-5c106cde.pth or resnet18.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e45969c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:14.355165Z",
     "iopub.status.busy": "2026-01-05T02:51:14.354799Z",
     "iopub.status.idle": "2026-01-05T02:51:15.490490Z",
     "shell.execute_reply": "2026-01-05T02:51:15.489685Z"
    },
    "papermill": {
     "duration": 1.141874,
     "end_time": "2026-01-05T02:51:15.492398",
     "exception": false,
     "start_time": "2026-01-05T02:51:14.350524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Weights Directory /kaggle/input/pretrained-pytorch-models\n",
      "Using ResNet18 weights: /kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2 — Model / Weights Setup (ResNet18 offline)\n",
    "# ============================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "# FIX: Import the functional interface as 'F' so SquarePad can use it\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def find_resnet18_weights(weights_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds a file that looks like ResNet18 ImageNet weights.\n",
    "    Typical filenames:\n",
    "      - resnet18-5c106cde.pth\n",
    "      - resnet18.pth\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] Weights Directory\", weights_dir)\n",
    "    wd = Path(weights_dir)\n",
    "    if not wd.exists():\n",
    "        raise FileNotFoundError(f\"Missing weights dataset. Expected directory: {weights_dir}\")\n",
    "\n",
    "    candidates = []\n",
    "    for p in wd.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in {\".pth\", \".pt\"}:\n",
    "            if \"resnet18\" in p.name.lower():\n",
    "                candidates.append(str(p))\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No resnet18 .pth/.pt file found under {weights_dir}\")\n",
    "\n",
    "    # Prefer torchvision-style hashed filename if present\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: (0 if re.search(r\"resnet18-.*\\.pth$\", os.path.basename(x).lower()) else 1, len(x))\n",
    "    )\n",
    "    return candidates_sorted[0]\n",
    "\n",
    "RESNET18_WEIGHTS = find_resnet18_weights(WEIGHTS_DIR)\n",
    "print(\"Using ResNet18 weights:\", RESNET18_WEIGHTS)\n",
    "\n",
    "class SquarePad:\n",
    "    \"\"\"\n",
    "    Pads the image with black pixels to make it square, preserving aspect ratio.\n",
    "    \"\"\"\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        max_wh = max(w, h)\n",
    "        p_left = (max_wh - w) // 2\n",
    "        p_top  = (max_wh - h) // 2\n",
    "        p_right = max_wh - w - p_left\n",
    "        p_bottom = max_wh - h - p_top\n",
    "        return F.pad(image, (p_left, p_top, p_right, p_bottom), 0, 'constant')\n",
    "\n",
    "def build_resnet18_feature_extractor(weights_path: str, device: str):\n",
    "    \"\"\"\n",
    "    Builds a ResNet18 backbone and loads ImageNet weights from a local .pth/.pt file.\n",
    "    Returns:\n",
    "      - feature extractor (outputs [B, 512])\n",
    "      - preprocessing transform (ImageNet-style)\n",
    "    \"\"\"\n",
    "    model = models.resnet18(weights=None)  # IMPORTANT: no internet download\n",
    "    state = torch.load(weights_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "    # Support both raw state_dict and checkpoint dicts\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "\n",
    "    # Remove common prefixes\n",
    "    cleaned = {}\n",
    "    for k, v in state.items():\n",
    "        k2 = k\n",
    "        for prefix in (\"module.\", \"model.\"):\n",
    "            if k2.startswith(prefix):\n",
    "                k2 = k2[len(prefix):]\n",
    "        cleaned[k2] = v\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
    "    if missing:\n",
    "        print(\"Warning: missing keys when loading weights:\", missing[:5], (\"...\" if len(missing) > 5 else \"\"))\n",
    "    if unexpected:\n",
    "        print(\"Warning: unexpected keys when loading weights:\", unexpected[:5], (\"...\" if len(unexpected) > 5 else \"\"))\n",
    "\n",
    "    extractor = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "    extractor.eval()\n",
    "    for p in extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    tfm = transforms.Compose([\n",
    "        SquarePad(), \n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ])\n",
    "    return extractor, tfm\n",
    "\n",
    "EXTRACTOR, IMG_TFM = build_resnet18_feature_extractor(RESNET18_WEIGHTS, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95005082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:15.501487Z",
     "iopub.status.busy": "2026-01-05T02:51:15.501223Z",
     "iopub.status.idle": "2026-01-05T02:51:15.584861Z",
     "shell.execute_reply": "2026-01-05T02:51:15.584206Z"
    },
    "papermill": {
     "duration": 0.090048,
     "end_time": "2026-01-05T02:51:15.586320",
     "exception": false,
     "start_time": "2026-01-05T02:51:15.496272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (1785, 9)\n",
      "test_df : (5, 3)\n",
      "sample_submission: (5, 2)\n",
      "train_wide: (357, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Dry_Clover_g</th>\n",
       "      <th>Dry_Dead_g</th>\n",
       "      <th>Dry_Green_g</th>\n",
       "      <th>Dry_Total_g</th>\n",
       "      <th>GDM_g</th>\n",
       "      <th>abs_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>31.9984</td>\n",
       "      <td>16.2751</td>\n",
       "      <td>48.2735</td>\n",
       "      <td>16.2750</td>\n",
       "      <td>/kaggle/input/csiro-biomass/train/ID1011485656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/ID1012260530.jpg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.6000</td>\n",
       "      <td>7.6000</td>\n",
       "      <td>7.6000</td>\n",
       "      <td>/kaggle/input/csiro-biomass/train/ID1012260530...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/ID1025234388.jpg</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>/kaggle/input/csiro-biomass/train/ID1025234388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/ID1028611175.jpg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>30.9703</td>\n",
       "      <td>24.2376</td>\n",
       "      <td>55.2079</td>\n",
       "      <td>24.2376</td>\n",
       "      <td>/kaggle/input/csiro-biomass/train/ID1028611175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/ID1035947949.jpg</td>\n",
       "      <td>0.4343</td>\n",
       "      <td>23.2239</td>\n",
       "      <td>10.5261</td>\n",
       "      <td>34.1844</td>\n",
       "      <td>10.9605</td>\n",
       "      <td>/kaggle/input/csiro-biomass/train/ID1035947949...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target_name              image_path  Dry_Clover_g  Dry_Dead_g  Dry_Green_g  \\\n",
       "0            train/ID1011485656.jpg        0.0000     31.9984      16.2751   \n",
       "1            train/ID1012260530.jpg        0.0000      0.0000       7.6000   \n",
       "2            train/ID1025234388.jpg        6.0500      0.0000       0.0000   \n",
       "3            train/ID1028611175.jpg        0.0000     30.9703      24.2376   \n",
       "4            train/ID1035947949.jpg        0.4343     23.2239      10.5261   \n",
       "\n",
       "target_name  Dry_Total_g    GDM_g  \\\n",
       "0                48.2735  16.2750   \n",
       "1                 7.6000   7.6000   \n",
       "2                 6.0500   6.0500   \n",
       "3                55.2079  24.2376   \n",
       "4                34.1844  10.9605   \n",
       "\n",
       "target_name                                           abs_path  \n",
       "0            /kaggle/input/csiro-biomass/train/ID1011485656...  \n",
       "1            /kaggle/input/csiro-biomass/train/ID1012260530...  \n",
       "2            /kaggle/input/csiro-biomass/train/ID1025234388...  \n",
       "3            /kaggle/input/csiro-biomass/train/ID1028611175...  \n",
       "4            /kaggle/input/csiro-biomass/train/ID1035947949...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3 — Data Loading (train/test/sample_submission)\n",
    "# ============================================\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "sample_sub = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "\n",
    "print(\"train_df:\", train_df.shape)\n",
    "print(\"test_df :\", test_df.shape)\n",
    "print(\"sample_submission:\", sample_sub.shape)\n",
    "\n",
    "TARGET_NAMES = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
    "\n",
    "def make_train_wide(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      image_path + TARGET_NAMES columns\n",
    "    Supports:\n",
    "      - modern long format: image_path, target_name, target\n",
    "      - fallback: image_path, target (assumes 5-row blocks per image)\n",
    "    \"\"\"\n",
    "    if {\"image_path\", \"target_name\", \"target\"}.issubset(df.columns):\n",
    "        wide = (\n",
    "            df.pivot_table(index=\"image_path\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "              .reset_index()\n",
    "        )\n",
    "        for t in TARGET_NAMES:\n",
    "            if t not in wide.columns:\n",
    "                wide[t] = np.nan\n",
    "        return wide[[\"image_path\"] + TARGET_NAMES]\n",
    "\n",
    "    if {\"image_path\", \"target\"}.issubset(df.columns):\n",
    "        paths = df[\"image_path\"].values\n",
    "        y = df[\"target\"].values\n",
    "        if len(df) % 5 != 0:\n",
    "            raise ValueError(\"Fallback parsing expected train rows multiple of 5.\")\n",
    "        unique_paths = paths[0::5]\n",
    "        wide = pd.DataFrame({\"image_path\": unique_paths})\n",
    "        for i, t in enumerate(TARGET_NAMES):\n",
    "            wide[t] = y[i::5]\n",
    "        return wide\n",
    "\n",
    "    raise ValueError(\"train.csv must have either (image_path,target_name,target) or (image_path,target).\")\n",
    "\n",
    "train_wide = make_train_wide(train_df)\n",
    "train_wide[\"abs_path\"] = train_wide[\"image_path\"].apply(lambda p: os.path.join(DATA_DIR, p))\n",
    "train_wide = train_wide.dropna(subset=TARGET_NAMES).reset_index(drop=True)\n",
    "\n",
    "print(\"train_wide:\", train_wide.shape)\n",
    "train_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869f909",
   "metadata": {
    "papermill": {
     "duration": 0.003601,
     "end_time": "2026-01-05T02:51:15.593572",
     "exception": false,
     "start_time": "2026-01-05T02:51:15.589971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. SET UP A CLASS OF RESNET18 FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca10877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:15.602095Z",
     "iopub.status.busy": "2026-01-05T02:51:15.601682Z",
     "iopub.status.idle": "2026-01-05T02:51:15.611795Z",
     "shell.execute_reply": "2026-01-05T02:51:15.611132Z"
    },
    "papermill": {
     "duration": 0.015914,
     "end_time": "2026-01-05T02:51:15.613165",
     "exception": false,
     "start_time": "2026-01-05T02:51:15.597251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4 — Feature Extraction Utilities (with debug prints)\n",
    "# ============================================\n",
    "class ImagePathDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f\"[CELL4] ImagePathDataset initialized with {len(self.image_paths)} paths\")\n",
    "        if len(self.image_paths) > 0:\n",
    "            print(\"[CELL4] First path:\", self.image_paths[0])\n",
    "            print(\"[CELL4] Last  path :\", self.image_paths[-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "        except (FileNotFoundError, OSError) as e:\n",
    "            if idx < 3:\n",
    "                print(f\"[CELL4][WARN] Failed to open image at idx={idx}: {p} | {type(e).__name__}\")\n",
    "            img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(image_paths, batch_size=64):\n",
    "    print(f\"[CELL4] extract_features called with {len(image_paths)} images, batch_size={batch_size}\")\n",
    "\n",
    "    ds = ImagePathDataset(image_paths, transform=IMG_TFM)\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=(DEVICE == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    feats = []\n",
    "    total_batches = len(loader)\n",
    "    print(f\"[CELL4] DataLoader ready: {total_batches} batches (num_workers=2, pin_memory={DEVICE=='cuda'})\")\n",
    "\n",
    "    for b_idx, batch in enumerate(loader):\n",
    "        if b_idx == 0:\n",
    "            print(\"[CELL4] First batch tensor shape:\", tuple(batch.shape))\n",
    "\n",
    "        batch = batch.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        out = EXTRACTOR(batch)          # [B, 512, 1, 1]\n",
    "        if b_idx == 0:\n",
    "            print(\"[CELL4] EXTRACTOR output shape (raw):\", tuple(out.shape))\n",
    "\n",
    "        out = out.view(out.size(0), -1) # [B, 512]\n",
    "        if b_idx == 0:\n",
    "            print(\"[CELL4] EXTRACTOR output shape (flattened):\", tuple(out.shape))\n",
    "\n",
    "        feats.append(out.cpu().numpy())\n",
    "\n",
    "        # Progress print every ~10% or at least every 10 batches\n",
    "        if total_batches > 0:\n",
    "            step = max(1, total_batches // 10)\n",
    "            if (b_idx + 1) % step == 0 or (b_idx + 1) == total_batches:\n",
    "                print(f\"[CELL4] Progress: batch {b_idx+1}/{total_batches}\")\n",
    "\n",
    "    feats_np = np.vstack(feats) if len(feats) else np.empty((0, 512), dtype=np.float32)\n",
    "    print(\"[CELL4] Done. Final feature matrix shape:\", feats_np.shape)\n",
    "    return feats_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78e5f0",
   "metadata": {
    "papermill": {
     "duration": 0.003462,
     "end_time": "2026-01-05T02:51:15.620227",
     "exception": false,
     "start_time": "2026-01-05T02:51:15.616765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Extract Train Images Features + Make sure the function in Cell 4 runs correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f3bb61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:15.629375Z",
     "iopub.status.busy": "2026-01-05T02:51:15.628606Z",
     "iopub.status.idle": "2026-01-05T02:51:30.967960Z",
     "shell.execute_reply": "2026-01-05T02:51:30.966908Z"
    },
    "papermill": {
     "duration": 15.346152,
     "end_time": "2026-01-05T02:51:30.969826",
     "exception": false,
     "start_time": "2026-01-05T02:51:15.623674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL4] extract_features called with 357 images, batch_size=64\n",
      "[CELL4] ImagePathDataset initialized with 357 paths\n",
      "[CELL4] First path: /kaggle/input/csiro-biomass/train/ID1011485656.jpg\n",
      "[CELL4] Last  path : /kaggle/input/csiro-biomass/train/ID983582017.jpg\n",
      "[CELL4] DataLoader ready: 6 batches (num_workers=2, pin_memory=True)\n",
      "[CELL4] First batch tensor shape: (64, 3, 224, 224)\n",
      "[CELL4] EXTRACTOR output shape (raw): (64, 512, 1, 1)\n",
      "[CELL4] EXTRACTOR output shape (flattened): (64, 512)\n",
      "[CELL4] Progress: batch 1/6\n",
      "[CELL4] Progress: batch 2/6\n",
      "[CELL4] Progress: batch 3/6\n",
      "[CELL4] Progress: batch 4/6\n",
      "[CELL4] Progress: batch 5/6\n",
      "[CELL4] Progress: batch 6/6\n",
      "[CELL4] Done. Final feature matrix shape: (357, 512)\n",
      "X_train: (357, 512)\n",
      "Y_train: (357, 5)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5 — Extract Train Features\n",
    "# ============================================\n",
    "X_train = extract_features(train_wide[\"abs_path\"].tolist(), batch_size=64)\n",
    "Y_train = train_wide[TARGET_NAMES].values.astype(np.float32)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"Y_train:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6a8a7",
   "metadata": {
    "papermill": {
     "duration": 0.004254,
     "end_time": "2026-01-05T02:51:30.978442",
     "exception": false,
     "start_time": "2026-01-05T02:51:30.974188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Train 5 Random Regression Models, 1 Random Forest per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb2c38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:51:30.988245Z",
     "iopub.status.busy": "2026-01-05T02:51:30.987960Z",
     "iopub.status.idle": "2026-01-05T02:52:47.863572Z",
     "shell.execute_reply": "2026-01-05T02:52:47.862823Z"
    },
    "papermill": {
     "duration": 76.886726,
     "end_time": "2026-01-05T02:52:47.869517",
     "exception": false,
     "start_time": "2026-01-05T02:51:30.982791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained RF models: ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6 — Training (one RandomForest per target)\n",
    "# ============================================\n",
    "models_rf = {}\n",
    "\n",
    "for i, t in enumerate(TARGET_NAMES):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, Y_train[:, i])\n",
    "    models_rf[t] = rf\n",
    "\n",
    "print(\"Trained RF models:\", list(models_rf.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7764e5d",
   "metadata": {
    "papermill": {
     "duration": 0.003629,
     "end_time": "2026-01-05T02:52:47.877006",
     "exception": false,
     "start_time": "2026-01-05T02:52:47.873377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Inference: Extract features once per unique test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b91672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:52:47.885771Z",
     "iopub.status.busy": "2026-01-05T02:52:47.885531Z",
     "iopub.status.idle": "2026-01-05T02:52:48.459519Z",
     "shell.execute_reply": "2026-01-05T02:52:48.458674Z"
    },
    "papermill": {
     "duration": 0.580196,
     "end_time": "2026-01-05T02:52:48.461071",
     "exception": false,
     "start_time": "2026-01-05T02:52:47.880875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL4] extract_features called with 1 images, batch_size=64\n",
      "[CELL4] ImagePathDataset initialized with 1 paths\n",
      "[CELL4] First path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] Last  path : /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] DataLoader ready: 1 batches (num_workers=2, pin_memory=True)\n",
      "[CELL4] First batch tensor shape: (1, 3, 224, 224)\n",
      "[CELL4] EXTRACTOR output shape (raw): (1, 512, 1, 1)\n",
      "[CELL4] EXTRACTOR output shape (flattened): (1, 512)\n",
      "[CELL4] Progress: batch 1/1\n",
      "[CELL4] Done. Final feature matrix shape: (1, 512)\n",
      "X_test: (1, 512)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>3.565780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>21.354683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "      <td>20.139318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>Dry_Total_g</td>\n",
       "      <td>40.043476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "      <td>GDM_g</td>\n",
       "      <td>21.055847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_path   target_name     target\n",
       "0  test/ID1001187975.jpg  Dry_Clover_g   3.565780\n",
       "1  test/ID1001187975.jpg    Dry_Dead_g  21.354683\n",
       "2  test/ID1001187975.jpg   Dry_Green_g  20.139318\n",
       "3  test/ID1001187975.jpg   Dry_Total_g  40.043476\n",
       "4  test/ID1001187975.jpg         GDM_g  21.055847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7 — Inference (extract features once per unique test image)\n",
    "# ============================================\n",
    "needed_cols = {\"sample_id\", \"image_path\", \"target_name\"}\n",
    "if not needed_cols.issubset(test_df.columns):\n",
    "    raise ValueError(f\"test.csv must contain columns {sorted(needed_cols)}\")\n",
    "\n",
    "unique_test_paths = test_df[\"image_path\"].drop_duplicates().tolist()\n",
    "unique_test_abs = [os.path.join(DATA_DIR, p) for p in unique_test_paths]\n",
    "\n",
    "X_test = extract_features(unique_test_abs, batch_size=64)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "\n",
    "pred_matrix = np.zeros((len(unique_test_paths), len(TARGET_NAMES)), dtype=np.float32)\n",
    "for j, t in enumerate(TARGET_NAMES):\n",
    "    pred_matrix[:, j] = models_rf[t].predict(X_test)\n",
    "\n",
    "pred_wide = pd.DataFrame(pred_matrix, columns=TARGET_NAMES)\n",
    "pred_wide[\"image_path\"] = unique_test_paths\n",
    "\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=\"image_path\",\n",
    "    var_name=\"target_name\",\n",
    "    value_name=\"target\"\n",
    ")\n",
    "\n",
    "pred_long.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd2427",
   "metadata": {
    "papermill": {
     "duration": 0.004091,
     "end_time": "2026-01-05T02:52:48.469542",
     "exception": false,
     "start_time": "2026-01-05T02:52:48.465451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06a3e776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:52:48.479642Z",
     "iopub.status.busy": "2026-01-05T02:52:48.479350Z",
     "iopub.status.idle": "2026-01-05T02:52:48.500100Z",
     "shell.execute_reply": "2026-01-05T02:52:48.499342Z"
    },
    "papermill": {
     "duration": 0.027772,
     "end_time": "2026-01-05T02:52:48.501395",
     "exception": false,
     "start_time": "2026-01-05T02:52:48.473623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   3.565780\n",
      "1    ID1001187975__Dry_Dead_g  21.354683\n",
      "2   ID1001187975__Dry_Green_g  20.139318\n",
      "3   ID1001187975__Dry_Total_g  40.043476\n",
      "4         ID1001187975__GDM_g  21.055847\n",
      "submission shape: (5, 2)\n",
      "Wrote submission.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 8 — Submission Export (match sample_submission ordering)\n",
    "# ============================================\n",
    "sub_pred = test_df[list(needed_cols)].merge(\n",
    "    pred_long,\n",
    "    on=[\"image_path\", \"target_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "submission = sample_sub[[\"sample_id\"]].merge(\n",
    "    sub_pred[[\"sample_id\", \"target\"]],\n",
    "    on=\"sample_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "assert list(submission.columns) == [\"sample_id\", \"target\"], \"Submission must have columns: sample_id, target\"\n",
    "\n",
    "print(submission.head())\n",
    "print(\"submission shape:\", submission.shape)\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Wrote submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c68cb",
   "metadata": {
    "papermill": {
     "duration": 0.004193,
     "end_time": "2026-01-05T02:52:48.509715",
     "exception": false,
     "start_time": "2026-01-05T02:52:48.505522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1f6cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:52:48.518963Z",
     "iopub.status.busy": "2026-01-05T02:52:48.518696Z",
     "iopub.status.idle": "2026-01-05T02:52:48.524889Z",
     "shell.execute_reply": "2026-01-05T02:52:48.524274Z"
    },
    "papermill": {
     "duration": 0.012777,
     "end_time": "2026-01-05T02:52:48.526414",
     "exception": false,
     "start_time": "2026-01-05T02:52:48.513637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGEMINI VERSION: TO COMPARE WITH CHAT GPT\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "GEMINI VERSION: TO COMPARE WITH CHAT GPT\n",
    "\"\"\"\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models, transforms\n",
    "# # FIX: Import the functional interface as 'F' so SquarePad can use it\n",
    "# import torchvision.transforms.functional as F\n",
    "\n",
    "# class SquarePad:\n",
    "#     \"\"\"\n",
    "#     Pads the image with black pixels to make it square, preserving aspect ratio.\n",
    "#     \"\"\"\n",
    "#     def __call__(self, image):\n",
    "#         w, h = image.size\n",
    "#         max_wh = max(w, h)\n",
    "#         p_left = (max_wh - w) // 2\n",
    "#         p_top  = (max_wh - h) // 2\n",
    "#         p_right = max_wh - w - p_left\n",
    "#         p_bottom = max_wh - h - p_top\n",
    "#         return F.pad(image, (p_left, p_top, p_right, p_bottom), 0, 'constant')\n",
    "\n",
    "# def get_feature_extractor(device, weight_path='/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth'):\n",
    "#     \"\"\"\n",
    "#     Loads ResNet18 weights safely by first mapping them to CPU.\n",
    "#     \"\"\"\n",
    "#     # 1. Initialize the model architecture\n",
    "#     model = models.resnet18(weights=None)\n",
    "    \n",
    "#     # 2. Load the weights from the local file\n",
    "#     try:\n",
    "#         # Load to CPU first to avoid device conflicts\n",
    "#         state_dict = torch.load(weight_path, map_location=\"cpu\", weights_only=False)\n",
    "#         model.load_state_dict(state_dict)\n",
    "#         print(f\"✅ Loaded local weights from {weight_path}\")\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"❌ Error: Could not find weights at {weight_path}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error loading state dict: {e}\")\n",
    "#         raise\n",
    "\n",
    "#     # 3. Remove classification head\n",
    "#     modules = list(model.children())[:-1] \n",
    "#     extractor = nn.Sequential(*modules)\n",
    "    \n",
    "#     # 4. Move to target device\n",
    "#     extractor.to(device)\n",
    "#     extractor.eval()\n",
    "    \n",
    "#     # 5. Freeze parameters\n",
    "#     for param in extractor.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "#     # 6. Define Transforms\n",
    "#     transform = transforms.Compose([\n",
    "#         SquarePad(), # Now works because 'F' is defined\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "#                              std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "#     return extractor, transform\n",
    "# # --- 2. Batched Feature Extraction ---\n",
    "# def extract_features_batched(df, image_root, batch_size=32, weight_path='/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth'):\n",
    "#     \"\"\"\n",
    "#     Extracts features using the locally loaded ResNet18 model.\n",
    "#     \"\"\"\n",
    "#     # Pass the specific weight path to the helper function\n",
    "#     extractor, transform = get_feature_extractor(DEVICE, weight_path=weight_path)\n",
    "    \n",
    "#     # Create Dataset\n",
    "#     # Ensure your BiomassDataset class is already defined before running this!\n",
    "#     dataset = BiomassDataset(df, image_root, transform=transform)\n",
    "    \n",
    "#     # DataLoader: num_workers=2 is efficient for Kaggle/Linux\n",
    "#     loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2) \n",
    "    \n",
    "#     features_list = []\n",
    "    \n",
    "#     print(f\"Extracting features for {len(df)} images (Batch Size: {batch_size})...\")\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_imgs in tqdm(loader, desc=\"Processing\"):\n",
    "#             batch_imgs = batch_imgs.to(DEVICE)\n",
    "            \n",
    "#             # Forward Pass\n",
    "#             preds = extractor(batch_imgs)      # Shape: [Batch, 512, 1, 1]\n",
    "#             preds = preds.view(preds.size(0), -1) # Flatten: [Batch, 512]\n",
    "            \n",
    "#             features_list.append(preds.cpu().numpy())\n",
    "            \n",
    "#     return np.vstack(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845b17a",
   "metadata": {
    "papermill": {
     "duration": 0.003951,
     "end_time": "2026-01-05T02:52:48.534430",
     "exception": false,
     "start_time": "2026-01-05T02:52:48.530479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# REMARK:OLD GEMINI CODES TO COMPARE WITH GPT, AND TO LEARN THE USEFULLNESS AND WHY BEHIND EACH SYNTAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94953a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T02:52:48.543438Z",
     "iopub.status.busy": "2026-01-05T02:52:48.543212Z",
     "iopub.status.idle": "2026-01-05T02:52:48.547888Z",
     "shell.execute_reply": "2026-01-05T02:52:48.547254Z"
    },
    "papermill": {
     "duration": 0.010668,
     "end_time": "2026-01-05T02:52:48.549147",
     "exception": false,
     "start_time": "2026-01-05T02:52:48.538479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPROCESS df-YY as the dataframe of test.csv. \\nKeep it to compare with GPT version of data loading test.csv vs. data loading train.csv\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PROCESS df-YY as the dataframe of test.csv. \n",
    "Keep it to compare with GPT version of data loading test.csv vs. data loading train.csv\n",
    "\"\"\"\n",
    "# import pandas as pd\n",
    "\n",
    "# def process_test_structure(csv_path):\n",
    "#     \"\"\"\n",
    "#     Parses the Kaggle-style test.csv into a format compatible with BiomassDataset.\n",
    "#     Input: Raw test CSV with 5 rows per image.\n",
    "#     Output: DataFrame with 1 row per image and 5 dummy target columns.\n",
    "#     \"\"\"\n",
    "#     # 1. Read the raw data\n",
    "#     raw_df = pd.read_csv(csv_path)\n",
    "    \n",
    "#     # 2. Extract unique images\n",
    "#     # The CSV lists 5 rows for every 1 image (one for each target type).\n",
    "#     # We slice with a stride of 5 to get unique image entries.\n",
    "#     df_unique = raw_df.iloc[::5].copy()\n",
    "    \n",
    "#     # 3. initialize the output DataFrame with the filename\n",
    "#     # We reset the index to ensure it starts from 0 to len(df)-1\n",
    "#     df_YY_new = df_unique[['image_path']].reset_index(drop=True)\n",
    "    \n",
    "#     # 4. Add dummy target columns\n",
    "#     # The Dataset class expects columns 1-5 to be float values. \n",
    "#     # Since this is inference, we fill them with 0.0.\n",
    "#     # The order MUST match the training set order.\n",
    "#     target_cols = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "    \n",
    "#     for col in target_cols:\n",
    "#         df_YY_new[col] = 0.0\n",
    "        \n",
    "#     return df_YY_new\n",
    "\n",
    "# # Apply the function\n",
    "# df_YY = process_test_structure('test.csv')\n",
    "\n",
    "# # Verify the structure\n",
    "# print(\"New df_YY shape:\", df_YY.shape)\n",
    "# print(df_YY.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 2847,
     "sourceId": 4958,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.137848,
   "end_time": "2026-01-05T02:52:51.406065",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-05T02:51:00.268217",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
