{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0432c6ec",
   "metadata": {
    "papermill": {
     "duration": 0.004875,
     "end_time": "2026-01-24T06:36:23.236164",
     "exception": false,
     "start_time": "2026-01-24T06:36:23.231289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. IMPORT LIBARIES + PATHS + REPRODUCBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5457f5a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:23.244966Z",
     "iopub.status.busy": "2026-01-24T06:36:23.244655Z",
     "iopub.status.idle": "2026-01-24T06:36:35.481336Z",
     "shell.execute_reply": "2026-01-24T06:36:35.480505Z"
    },
    "papermill": {
     "duration": 12.242996,
     "end_time": "2026-01-24T06:36:35.482929",
     "exception": false,
     "start_time": "2026-01-24T06:36:23.239933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DATA_DIR: /kaggle/input/csiro-biomass\n",
      "✅ WEIGHTS_DIR: /kaggle/input/pretrained-pytorch-models\n",
      "✅ DEVICE: cuda\n",
      "✅ IMG_SIZE: 224\n",
      "✅ Train CSV: /kaggle/input/csiro-biomass/train.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1 — Imports + Paths + Reproducibility\n",
    "# ============================================\n",
    "\"\"\"\n",
    "Kaggle to GitHub Sync Configuration\n",
    "Repository: CODES-ON-KAGGLE\n",
    "\"\"\"\n",
    "# Import\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ✅ Competition directory (as you stated)\n",
    "DATA_DIR = \"/kaggle/input/csiro-biomass\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "# SAMPLE_SUB_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# ✅ Pretrained weights dataset input for model resnet18\n",
    "WEIGHTS_DIR = \"/kaggle/input/pretrained-pytorch-models\"\n",
    "\n",
    "# Inference\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ✅ NotebookA image size (introduced once because Notebook A had no size variable)\n",
    "IMG_SIZE = 224  # used everywhere for resize-only transforms (no pad, no crop)\n",
    "\n",
    "# Safety checks (fail fast if something isn't mounted)\n",
    "for p in [DATA_DIR, WEIGHTS_DIR, TRAIN_CSV, TEST_CSV]:\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Missing expected path: {p}\")\n",
    "\n",
    "print(\"✅ DATA_DIR:\", DATA_DIR)\n",
    "print(\"✅ WEIGHTS_DIR:\", WEIGHTS_DIR)\n",
    "print(\"✅ DEVICE:\", DEVICE)\n",
    "print(\"✅ IMG_SIZE:\", IMG_SIZE)\n",
    "print(\"✅ Train CSV:\", TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824abf73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:35.492219Z",
     "iopub.status.busy": "2026-01-24T06:36:35.491490Z",
     "iopub.status.idle": "2026-01-24T06:36:35.495201Z",
     "shell.execute_reply": "2026-01-24T06:36:35.494441Z"
    },
    "papermill": {
     "duration": 0.00982,
     "end_time": "2026-01-24T06:36:35.496735",
     "exception": false,
     "start_time": "2026-01-24T06:36:35.486915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1.5 — Letterboxing REMOVED\n",
    "# ============================================\n",
    "# IMPORTANT:\n",
    "# - Letterboxing (pad-to-square / resize-with-padding) has been removed/disabled entirely.\n",
    "# - No SquarePad / Pad / keep-aspect-ratio+pad is used anywhere in transforms.\n",
    "# - All pipelines use RESIZE-ONLY: Resize((IMG_SIZE, IMG_SIZE)) with existing ToTensor/Normalize.\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba23c5",
   "metadata": {
    "papermill": {
     "duration": 0.003632,
     "end_time": "2026-01-24T06:36:35.503979",
     "exception": false,
     "start_time": "2026-01-24T06:36:35.500347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. SETUP WEIGHTS FOR THE OFFLINE RESNET 18\n",
    "Since we run code when the Internet is off, we have to manually input a dataset on Kaggle\n",
    "that contains ResNet18 ImageNet weights.\n",
    "The ResNet18 ImageNet weights will be named resnet18-5c106cde.pth or resnet18.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29699fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:35.512160Z",
     "iopub.status.busy": "2026-01-24T06:36:35.511866Z",
     "iopub.status.idle": "2026-01-24T06:36:36.875219Z",
     "shell.execute_reply": "2026-01-24T06:36:36.874350Z"
    },
    "papermill": {
     "duration": 1.369474,
     "end_time": "2026-01-24T06:36:36.876931",
     "exception": false,
     "start_time": "2026-01-24T06:36:35.507457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] weights_dir: /kaggle/input/pretrained-pytorch-models\n",
      "[DEBUG] resnet18 candidates found: 1\n",
      "[DEBUG] first few candidates: ['/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth']\n",
      "[DEBUG] RESNET18_WEIGHTS selected: /kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth\n",
      "[DEBUG] Feature extractor ready.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2a — Model / Weights Setup (ResNet18 offline) + Robust Loader + Debug Prints\n",
    "# ============================================\n",
    "def find_resnet18_weights(weights_dir: str) -> str:\n",
    "    print(\"[DEBUG] weights_dir:\", weights_dir)\n",
    "\n",
    "    wd = Path(weights_dir)\n",
    "    if not wd.exists():\n",
    "        raise FileNotFoundError(f\"Missing weights dataset. Expected directory: {weights_dir}\")\n",
    "\n",
    "    candidates = []\n",
    "    for p in wd.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in {\".pth\", \".pt\"} and \"resnet18\" in p.name.lower():\n",
    "            candidates.append(str(p))\n",
    "\n",
    "    print(\"[DEBUG] resnet18 candidates found:\", len(candidates))\n",
    "    if candidates:\n",
    "        print(\"[DEBUG] first few candidates:\", candidates[:5])\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No resnet18 .pth/.pt file found under {weights_dir}\")\n",
    "\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: (0 if re.search(r\"resnet18-.*\\.pth$\", os.path.basename(x).lower()) else 1, len(x))\n",
    "    )\n",
    "    chosen = candidates_sorted[0]\n",
    "    print(\"[DEBUG] RESNET18_WEIGHTS selected:\", chosen)\n",
    "    return chosen\n",
    "\n",
    "RESNET18_WEIGHTS = find_resnet18_weights(WEIGHTS_DIR)\n",
    "\n",
    "def _to_state_dict(obj):\n",
    "    \"\"\"Convert various checkpoint formats into a state_dict dict.\"\"\"\n",
    "    if isinstance(obj, nn.Module):\n",
    "        return obj.state_dict()\n",
    "    if isinstance(obj, dict):\n",
    "        if \"state_dict\" in obj and isinstance(obj[\"state_dict\"], dict):\n",
    "            return obj[\"state_dict\"]\n",
    "        # If it already looks like a state_dict\n",
    "        if all(isinstance(k, str) for k in obj.keys()):\n",
    "            return obj\n",
    "    raise TypeError(f\"Unsupported checkpoint type: {type(obj)}\")\n",
    "\n",
    "def build_resnet18_feature_extractor(weights_path: str, device: str):\n",
    "    model = models.resnet18(weights=None)  # no internet download\n",
    "    raw = torch.load(weights_path, map_location=\"cpu\", weights_only=False)\n",
    "    state = _to_state_dict(raw)\n",
    "\n",
    "    cleaned = {}\n",
    "    for k, v in state.items():\n",
    "        k2 = k\n",
    "        for prefix in (\"module.\", \"model.\"):\n",
    "            if k2.startswith(prefix):\n",
    "                k2 = k2[len(prefix):]\n",
    "        cleaned[k2] = v\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
    "    if missing:\n",
    "        print(\"Warning: missing keys when loading weights:\", missing[:5], (\"...\" if len(missing) > 5 else \"\"))\n",
    "    if unexpected:\n",
    "        print(\"Warning: unexpected keys when loading weights:\", unexpected[:5], (\"...\" if len(unexpected) > 5 else \"\"))\n",
    "\n",
    "    extractor = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "    extractor.eval()\n",
    "    for p in extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # ✅ Resize-only (no padding / no cropping)\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ])\n",
    "    return extractor, tfm\n",
    "\n",
    "EXTRACTOR, IMG_TFM = build_resnet18_feature_extractor(RESNET18_WEIGHTS, DEVICE)\n",
    "print(\"[DEBUG] Feature extractor ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03090c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:36.887615Z",
     "iopub.status.busy": "2026-01-24T06:36:36.887182Z",
     "iopub.status.idle": "2026-01-24T06:36:37.173017Z",
     "shell.execute_reply": "2026-01-24T06:36:37.172218Z"
    },
    "papermill": {
     "duration": 0.29297,
     "end_time": "2026-01-24T06:36:37.174516",
     "exception": false,
     "start_time": "2026-01-24T06:36:36.881546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] weights_dir: /kaggle/input/pretrained-pytorch-models\n",
      "[DEBUG] resnet18 candidates found: 1\n",
      "[DEBUG] first few candidates: ['/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth']\n",
      "[DEBUG] RESNET18_WEIGHTS selected: /kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth\n",
      "[DEBUG] Feature extractor ready.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2b — Model / Weights Setup (ResNet18 offline) + Robust Loader + Debug Prints\n",
    "# (Duplicated in Notebook A — preserved as-is structurally, with the same resize-only fix)\n",
    "# ============================================\n",
    "def find_resnet18_weights(weights_dir: str) -> str:\n",
    "    print(\"[DEBUG] weights_dir:\", weights_dir)\n",
    "\n",
    "    wd = Path(weights_dir)\n",
    "    if not wd.exists():\n",
    "        raise FileNotFoundError(f\"Missing weights dataset. Expected directory: {weights_dir}\")\n",
    "\n",
    "    candidates = []\n",
    "    for p in wd.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in {\".pth\", \".pt\"} and \"resnet18\" in p.name.lower():\n",
    "            candidates.append(str(p))\n",
    "\n",
    "    print(\"[DEBUG] resnet18 candidates found:\", len(candidates))\n",
    "    if candidates:\n",
    "        print(\"[DEBUG] first few candidates:\", candidates[:5])\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No resnet18 .pth/.pt file found under {weights_dir}\")\n",
    "\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: (0 if re.search(r\"resnet18-.*\\.pth$\", os.path.basename(x).lower()) else 1, len(x))\n",
    "    )\n",
    "    chosen = candidates_sorted[0]\n",
    "    print(\"[DEBUG] RESNET18_WEIGHTS selected:\", chosen)\n",
    "    return chosen\n",
    "\n",
    "RESNET18_WEIGHTS = find_resnet18_weights(WEIGHTS_DIR)\n",
    "\n",
    "def _to_state_dict(obj):\n",
    "    \"\"\"Convert various checkpoint formats into a state_dict dict.\"\"\"\n",
    "    if isinstance(obj, nn.Module):\n",
    "        return obj.state_dict()\n",
    "    if isinstance(obj, dict):\n",
    "        if \"state_dict\" in obj and isinstance(obj[\"state_dict\"], dict):\n",
    "            return obj[\"state_dict\"]\n",
    "        # If it already looks like a state_dict\n",
    "        if all(isinstance(k, str) for k in obj.keys()):\n",
    "            return obj\n",
    "    raise TypeError(f\"Unsupported checkpoint type: {type(obj)}\")\n",
    "\n",
    "def build_resnet18_feature_extractor(weights_path: str, device: str):\n",
    "    model = models.resnet18(weights=None)  # no internet download\n",
    "    raw = torch.load(weights_path, map_location=\"cpu\", weights_only=False)\n",
    "    state = _to_state_dict(raw)\n",
    "\n",
    "    cleaned = {}\n",
    "    for k, v in state.items():\n",
    "        k2 = k\n",
    "        for prefix in (\"module.\", \"model.\"):\n",
    "            if k2.startswith(prefix):\n",
    "                k2 = k2[len(prefix):]\n",
    "        cleaned[k2] = v\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
    "    if missing:\n",
    "        print(\"Warning: missing keys when loading weights:\", missing[:5], (\"...\" if len(missing) > 5 else \"\"))\n",
    "    if unexpected:\n",
    "        print(\"Warning: unexpected keys when loading weights:\", unexpected[:5], (\"...\" if len(unexpected) > 5 else \"\"))\n",
    "\n",
    "    extractor = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "    extractor.eval()\n",
    "    for p in extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # ✅ Resize-only (no padding / no cropping)\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ])\n",
    "    return extractor, tfm\n",
    "\n",
    "EXTRACTOR, IMG_TFM = build_resnet18_feature_extractor(RESNET18_WEIGHTS, DEVICE)\n",
    "print(\"[DEBUG] Feature extractor ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234c7386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:37.183994Z",
     "iopub.status.busy": "2026-01-24T06:36:37.183465Z",
     "iopub.status.idle": "2026-01-24T06:36:37.188780Z",
     "shell.execute_reply": "2026-01-24T06:36:37.188148Z"
    },
    "papermill": {
     "duration": 0.011654,
     "end_time": "2026-01-24T06:36:37.190287",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.178633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Defined get_tta_transforms() for validation/inference-only TTA (resize-only).\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2.5 — AUGMENTATIONS — TTA Views (validation/inference-only)\n",
    "# (Integrated from LB-0-57-CODE idea: original/hflip/vflip)\n",
    "# ============================================\n",
    "def get_tta_transforms():\n",
    "    \"\"\"\n",
    "    Returns a LIST of torchvision transform pipelines for TTA.\n",
    "    Each pipeline is a different \"view\" of the image.\n",
    "    NOTE: Applied ONLY for validation/inference (not training).\n",
    "    \"\"\"\n",
    "    # Base pipeline mirrors IMG_TFM normalization config.\n",
    "    base_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),  # ✅ resize-only (no pad, no crop)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # View 1: Original\n",
    "    original_view = transforms.Compose([\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 2: Horizontal Flip (always)\n",
    "    hflip_view = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 3: Vertical Flip (always)\n",
    "    vflip_view = transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(p=1.0),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    return [original_view, hflip_view, vflip_view]\n",
    "\n",
    "print(\"✅ Defined get_tta_transforms() for validation/inference-only TTA (resize-only).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034fa749",
   "metadata": {
    "papermill": {
     "duration": 0.003803,
     "end_time": "2026-01-24T06:36:37.197926",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.194123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae3fb92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:37.206708Z",
     "iopub.status.busy": "2026-01-24T06:36:37.206474Z",
     "iopub.status.idle": "2026-01-24T06:36:37.278498Z",
     "shell.execute_reply": "2026-01-24T06:36:37.277650Z"
    },
    "papermill": {
     "duration": 0.078368,
     "end_time": "2026-01-24T06:36:37.280121",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.201753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory for ground truth: /kaggle/input/csiro-biomass/test\n",
      "✅ Found 1 images in directory.\n",
      "train_df: (1785, 9)\n",
      "train_wide: (357, 7)\n",
      "[DEBUG] train_df columns: ['sample_id', 'image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm', 'target_name', 'target']\n",
      "[DEBUG] train_wide rows : 357\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3 — Data Loading (train/test)\n",
    "# ============================================\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "TEST_FOLDER_NAME = \"test\"\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, TEST_FOLDER_NAME)\n",
    "\n",
    "print(f\"Scanning directory for ground truth: {TEST_IMG_DIR}\")\n",
    "\n",
    "# 3. MANUAL DIRECTORY SCAN\n",
    "# We ignore the provided test.csv and look at the disk\n",
    "try:\n",
    "    # Get all image files sorted alphabetically\n",
    "    all_test_images = sorted([\n",
    "        f for f in os.listdir(TEST_IMG_DIR)\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ WARN: Test directory not found (Local run?). Creating empty DF.\")\n",
    "    all_test_images = []\n",
    "\n",
    "print(f\"✅ Found {len(all_test_images)} images in directory.\")\n",
    "\n",
    "# 4. CONSTRUCT COMPATIBLE DATAFRAME\n",
    "# Trang's code later does: os.path.join(DATA_DIR, p)\n",
    "# So we must ensure 'p' includes the folder name, e.g., \"test/image_01.jpg\"\n",
    "data = []\n",
    "for filename in all_test_images:\n",
    "    relative_path = os.path.join(TEST_FOLDER_NAME, filename)\n",
    "    data.append({\n",
    "        \"image_path\": relative_path,  # This fixes the pathing\n",
    "        \"sample_id\": filename,        # Placeholder\n",
    "        \"target_name\": \"GDM_g\"        # Placeholder (not used for final submission generation)\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame(data)\n",
    "\n",
    "print(\"train_df:\", train_df.shape)\n",
    "\n",
    "# ===============================================================\n",
    "# Core Strategy (from LB-0-57-DESCRIPTION): predict 3, reconstruct 5\n",
    "# ===============================================================\n",
    "# 5 targets present in the dataset (used for parsing / completeness checks)\n",
    "ALL_TARGET_NAMES = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
    "\n",
    "# 3 targets to train/predict (exactly as specified in LB-0-57-DESCRIPTION)\n",
    "CORE_TARGET_NAMES = [\"Dry_Total_g\", \"GDM_g\", \"Dry_Green_g\"]\n",
    "\n",
    "# 5 targets to output for submission (order can be any; we keep LB-style ordering)\n",
    "SUBMISSION_TARGET_NAMES = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "\n",
    "def make_train_wide(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      image_path + ALL_TARGET_NAMES columns\n",
    "    Supports:\n",
    "      - modern long format: image_path, target_name, target\n",
    "      - fallback: image_path, target (assumes 5-row blocks per image)\n",
    "    \"\"\"\n",
    "    if {\"image_path\", \"target_name\", \"target\"}.issubset(df.columns):\n",
    "        wide = (\n",
    "            df.pivot_table(index=\"image_path\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "              .reset_index()\n",
    "        )\n",
    "        for t in ALL_TARGET_NAMES:\n",
    "            if t not in wide.columns:\n",
    "                wide[t] = np.nan\n",
    "        return wide[[\"image_path\"] + ALL_TARGET_NAMES]\n",
    "\n",
    "    if {\"image_path\", \"target\"}.issubset(df.columns):\n",
    "        paths = df[\"image_path\"].values\n",
    "        y = df[\"target\"].values\n",
    "        if len(df) % 5 != 0:\n",
    "            raise ValueError(\"Fallback parsing expected train rows multiple of 5.\")\n",
    "        unique_paths = paths[0::5]\n",
    "        wide = pd.DataFrame({\"image_path\": unique_paths})\n",
    "        for i, t in enumerate(ALL_TARGET_NAMES):\n",
    "            wide[t] = y[i::5]\n",
    "        return wide\n",
    "\n",
    "    raise ValueError(\"train.csv must have either (image_path,target_name,target) or (image_path,target).\")\n",
    "\n",
    "train_wide = make_train_wide(train_df)\n",
    "train_wide[\"abs_path\"] = train_wide[\"image_path\"].apply(lambda p: os.path.join(DATA_DIR, p))\n",
    "train_wide = train_wide.dropna(subset=ALL_TARGET_NAMES).reset_index(drop=True)\n",
    "\n",
    "print(\"train_wide:\", train_wide.shape)\n",
    "train_wide.head()\n",
    "\n",
    "# Fail-fast checks (put after train_wide is built)\n",
    "print(\"[DEBUG] train_df columns:\", list(train_df.columns))\n",
    "print(\"[DEBUG] train_wide rows :\", len(train_wide))\n",
    "\n",
    "if len(train_wide) == 0:\n",
    "    raise ValueError(\"train_wide is empty. train.csv parsing likely mismatched the actual format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92f42e",
   "metadata": {
    "papermill": {
     "duration": 0.004244,
     "end_time": "2026-01-24T06:36:37.288660",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.284416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. SET UP A CLASS OF RESNET18 FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa3137b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:37.298082Z",
     "iopub.status.busy": "2026-01-24T06:36:37.297269Z",
     "iopub.status.idle": "2026-01-24T06:36:37.306313Z",
     "shell.execute_reply": "2026-01-24T06:36:37.305754Z"
    },
    "papermill": {
     "duration": 0.015144,
     "end_time": "2026-01-24T06:36:37.307627",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.292483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4 — Feature Extraction Utilities (stable for Kaggle submission)\n",
    "# ============================================\n",
    "BATCH_SIZE = 2  # keep your setting\n",
    "\n",
    "NUM_WORKERS = 0  # ✅ stable setting for Kaggle submission runs\n",
    "\n",
    "class ImagePathDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f\"[CELL4] Dataset init: {len(self.image_paths)} images\")\n",
    "        if self.image_paths:\n",
    "            print(\"[CELL4] Example path:\", self.image_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            if idx < 3:\n",
    "                print(f\"[CELL4][WARN] Open failed idx={idx}: {p} | {type(e).__name__}\")\n",
    "            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(image_paths, batch_size=BATCH_SIZE, transform=IMG_TFM):\n",
    "    print(f\"[CELL4] extract_features: {len(image_paths)} images | batch_size={batch_size} | workers={NUM_WORKERS}\")\n",
    "\n",
    "    ds = ImagePathDataset(image_paths, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,           # ✅ stable\n",
    "        pin_memory=(DEVICE == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    feats = []\n",
    "    total_batches = len(loader)\n",
    "    print(f\"[CELL4] total_batches={total_batches}\")\n",
    "\n",
    "    for b_idx, batch in enumerate(loader):\n",
    "        if b_idx == 0:\n",
    "            print(\"[CELL4] First batch:\", tuple(batch.shape))\n",
    "\n",
    "        batch = batch.to(DEVICE, non_blocking=True)\n",
    "        out = EXTRACTOR(batch)              # [B, 512, 1, 1]\n",
    "        out = out.view(out.size(0), -1)     # [B, 512]\n",
    "        feats.append(out.cpu().numpy())\n",
    "\n",
    "        if (b_idx + 1) == 1 or (b_idx + 1) == total_batches or (b_idx + 1) % max(1, total_batches // 5) == 0:\n",
    "            print(f\"[CELL4] Progress: {b_idx+1}/{total_batches}\")\n",
    "\n",
    "    feats_np = np.vstack(feats) if feats else np.empty((0, 512), dtype=np.float32)\n",
    "    print(\"[CELL4] features shape:\", feats_np.shape)\n",
    "    return feats_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4ad1d",
   "metadata": {
    "papermill": {
     "duration": 0.004686,
     "end_time": "2026-01-24T06:36:37.316225",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.311539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Extract Train Images Features + Make sure the function in Cell 4 runs correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4abcf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:36:37.325055Z",
     "iopub.status.busy": "2026-01-24T06:36:37.324559Z",
     "iopub.status.idle": "2026-01-24T06:37:03.005245Z",
     "shell.execute_reply": "2026-01-24T06:37:03.004354Z"
    },
    "papermill": {
     "duration": 25.686955,
     "end_time": "2026-01-24T06:37:03.006946",
     "exception": false,
     "start_time": "2026-01-24T06:36:37.319991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL4] extract_features: 357 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 357 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/train/ID1011485656.jpg\n",
      "[CELL4] total_batches=23\n",
      "[CELL4] First batch: (16, 3, 224, 224)\n",
      "[CELL4] Progress: 1/23\n",
      "[CELL4] Progress: 4/23\n",
      "[CELL4] Progress: 8/23\n",
      "[CELL4] Progress: 12/23\n",
      "[CELL4] Progress: 16/23\n",
      "[CELL4] Progress: 20/23\n",
      "[CELL4] Progress: 23/23\n",
      "[CELL4] features shape: (357, 512)\n",
      "X_train: (357, 512)\n",
      "Y_train: (357, 3)\n",
      "Core targets: ['Dry_Total_g', 'GDM_g', 'Dry_Green_g']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5 — Extract Train Features\n",
    "# ============================================\n",
    "X_train = extract_features(train_wide[\"abs_path\"].tolist(), batch_size=16)\n",
    "\n",
    "# ✅ Core Strategy: train labels are ONLY the 3 core targets\n",
    "Y_train = train_wide[CORE_TARGET_NAMES].values.astype(np.float32)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"Y_train:\", Y_train.shape)\n",
    "print(\"Core targets:\", CORE_TARGET_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc843f",
   "metadata": {
    "papermill": {
     "duration": 0.00459,
     "end_time": "2026-01-24T06:37:03.016397",
     "exception": false,
     "start_time": "2026-01-24T06:37:03.011807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Train 5 Random Regression Models, 1 Random Forest per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6bf002c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:37:03.025968Z",
     "iopub.status.busy": "2026-01-24T06:37:03.025697Z",
     "iopub.status.idle": "2026-01-24T06:38:06.999372Z",
     "shell.execute_reply": "2026-01-24T06:38:06.998596Z"
    },
    "papermill": {
     "duration": 63.984803,
     "end_time": "2026-01-24T06:38:07.005350",
     "exception": false,
     "start_time": "2026-01-24T06:37:03.020547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained RF models (core targets): ['Dry_Total_g', 'GDM_g', 'Dry_Green_g']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6 — Training (one RandomForest per CORE target)\n",
    "# ============================================\n",
    "models_rf = {}\n",
    "\n",
    "for i, t in enumerate(CORE_TARGET_NAMES):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        n_jobs=2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, Y_train[:, i])\n",
    "    models_rf[t] = rf\n",
    "\n",
    "print(\"Trained RF models (core targets):\", list(models_rf.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2a2de",
   "metadata": {
    "papermill": {
     "duration": 0.004143,
     "end_time": "2026-01-24T06:38:07.013751",
     "exception": false,
     "start_time": "2026-01-24T06:38:07.009608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Inference: Extract features once per unique test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e201a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:38:07.023566Z",
     "iopub.status.busy": "2026-01-24T06:38:07.023226Z",
     "iopub.status.idle": "2026-01-24T06:38:07.881456Z",
     "shell.execute_reply": "2026-01-24T06:38:07.880888Z"
    },
    "papermill": {
     "duration": 0.865224,
     "end_time": "2026-01-24T06:38:07.883082",
     "exception": false,
     "start_time": "2026-01-24T06:38:07.017858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL7] Using TTA views: 3 (validation/inference-only)\n",
      "[CELL7] Extracting features for TTA view 1/3 ...\n",
      "[CELL4] extract_features: 1 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] total_batches=1\n",
      "[CELL4] First batch: (1, 3, 224, 224)\n",
      "[CELL4] Progress: 1/1\n",
      "[CELL4] features shape: (1, 512)\n",
      "[CELL7] Extracting features for TTA view 2/3 ...\n",
      "[CELL4] extract_features: 1 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] total_batches=1\n",
      "[CELL4] First batch: (1, 3, 224, 224)\n",
      "[CELL4] Progress: 1/1\n",
      "[CELL4] features shape: (1, 512)\n",
      "[CELL7] Extracting features for TTA view 3/3 ...\n",
      "[CELL4] extract_features: 1 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] total_batches=1\n",
      "[CELL4] First batch: (1, 3, 224, 224)\n",
      "[CELL4] Progress: 1/1\n",
      "[CELL4] features shape: (1, 512)\n",
      "[CELL7] Averaging predictions across TTA views for CORE targets ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7 — Inference (extract features once per unique test image) + TTA + 3->5 reconstruction\n",
    "# ============================================\n",
    "needed_cols = {\"sample_id\", \"image_path\", \"target_name\"}\n",
    "if not needed_cols.issubset(test_df.columns):\n",
    "    raise ValueError(f\"test.csv must contain columns {sorted(needed_cols)}\")\n",
    "\n",
    "unique_test_paths = test_df[\"image_path\"].drop_duplicates().tolist()\n",
    "unique_test_abs = [os.path.join(DATA_DIR, p) for p in unique_test_paths]\n",
    "\n",
    "# ----------------------------\n",
    "# TTA (validation/inference-only)\n",
    "# ----------------------------\n",
    "tta_transforms = get_tta_transforms()\n",
    "print(f\"[CELL7] Using TTA views: {len(tta_transforms)} (validation/inference-only)\")\n",
    "\n",
    "# Extract features for each TTA view\n",
    "X_test_views = []\n",
    "for i, tfm in enumerate(tta_transforms):\n",
    "    print(f\"[CELL7] Extracting features for TTA view {i+1}/{len(tta_transforms)} ...\")\n",
    "    X_view = extract_features(unique_test_abs, batch_size=16, transform=tfm)\n",
    "    X_test_views.append(X_view)\n",
    "\n",
    "# ----------------------------\n",
    "# Predict ONLY 3 core targets, then reconstruct full 5\n",
    "# ----------------------------\n",
    "print(\"[CELL7] Averaging predictions across TTA views for CORE targets ...\")\n",
    "pred_core = np.zeros((len(unique_test_paths), len(CORE_TARGET_NAMES)), dtype=np.float32)\n",
    "\n",
    "for j, t in enumerate(CORE_TARGET_NAMES):\n",
    "    view_preds = []\n",
    "    for X_view in X_test_views:\n",
    "        view_preds.append(models_rf[t].predict(X_view))\n",
    "    pred_core[:, j] = np.mean(np.stack(view_preds, axis=0), axis=0).astype(np.float32)\n",
    "\n",
    "# Split core predictions\n",
    "idx_total = CORE_TARGET_NAMES.index(\"Dry_Total_g\")\n",
    "idx_gdm   = CORE_TARGET_NAMES.index(\"GDM_g\")\n",
    "idx_green = CORE_TARGET_NAMES.index(\"Dry_Green_g\")\n",
    "\n",
    "pred_total = np.maximum(0, pred_core[:, idx_total]).astype(np.float32)\n",
    "pred_gdm   = np.maximum(0, pred_core[:, idx_gdm]).astype(np.float32)\n",
    "pred_green = np.maximum(0, pred_core[:, idx_green]).astype(np.float32)\n",
    "\n",
    "# Reconstruct remaining 2 targets (LB-0-57 logic)\n",
    "pred_clover = np.maximum(0, pred_gdm - pred_green).astype(np.float32)  # Clover = max(0, GDM - Green)\n",
    "pred_dead   = np.maximum(0, pred_total - pred_gdm).astype(np.float32)  # Dead   = max(0, Total - GDM)\n",
    "\n",
    "# Build wide 5-target predictions (submission-ready)\n",
    "pred_wide = pd.DataFrame({\n",
    "    \"image_path\": unique_test_paths,\n",
    "    \"Dry_Green_g\": pred_green,\n",
    "    \"Dry_Dead_g\": pred_dead,\n",
    "    \"Dry_Clover_g\": pred_clover,\n",
    "    \"GDM_g\": pred_gdm,\n",
    "    \"Dry_Total_g\": pred_total,\n",
    "})\n",
    "\n",
    "# Ensure expected columns exist and order is consistent\n",
    "pred_wide = pred_wide[[\"image_path\"] + SUBMISSION_TARGET_NAMES]\n",
    "\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=\"image_path\",\n",
    "    value_vars=SUBMISSION_TARGET_NAMES,\n",
    "    var_name=\"target_name\",\n",
    "    value_name=\"target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec015f4",
   "metadata": {
    "papermill": {
     "duration": 0.004526,
     "end_time": "2026-01-24T06:38:07.892223",
     "exception": false,
     "start_time": "2026-01-24T06:38:07.887697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ad070f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:38:07.902212Z",
     "iopub.status.busy": "2026-01-24T06:38:07.901757Z",
     "iopub.status.idle": "2026-01-24T06:38:07.922409Z",
     "shell.execute_reply": "2026-01-24T06:38:07.921574Z"
    },
    "papermill": {
     "duration": 0.027408,
     "end_time": "2026-01-24T06:38:07.923957",
     "exception": false,
     "start_time": "2026-01-24T06:38:07.896549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing submission directly from predictions...\n",
      "Step 2: Constructing sample_id...\n",
      "✅ Submission saved to: /kaggle/working/submission.csv\n",
      "   Shape: (5, 2)\n",
      "   Unique Targets: ['Dry_Green_g' 'Dry_Dead_g' 'Dry_Clover_g' 'GDM_g' 'Dry_Total_g']\n",
      "   Head:\n",
      "                    sample_id     target\n",
      "2  ID1001187975__Dry_Clover_g   5.321133\n",
      "1    ID1001187975__Dry_Dead_g  21.870434\n",
      "0   ID1001187975__Dry_Green_g  24.901474\n",
      "4   ID1001187975__Dry_Total_g  52.093040\n",
      "3         ID1001187975__GDM_g  30.222607\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 8 — SUBMISSION\n",
    "# ============================================\n",
    "pred_long.head()\n",
    "\n",
    "SUBMISSION_PATH = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "def generate_submission_direct(pred_long: pd.DataFrame, output_path: str = SUBMISSION_PATH):\n",
    "    print(\"Step 1: Preparing submission directly from predictions...\")\n",
    "\n",
    "    # We work on a copy to avoid SettingWithCopy warnings\n",
    "    sub = pred_long.copy()\n",
    "\n",
    "    # --- A. CLEAN THE ID ---\n",
    "    # In Cell 3 (Hijack), we set image_path = \"test/image_01.jpg\"\n",
    "    # We need just \"image_01\" for the sample_id.\n",
    "\n",
    "    # 1. Strip directory prefix (get \"image_01.jpg\")\n",
    "    sub['filename'] = sub['image_path'].apply(lambda x: os.path.basename(str(x)))\n",
    "\n",
    "    # 2. Strip extension (get \"image_01\")\n",
    "    sub['image_id'] = sub['filename'].apply(lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "    # --- B. CONSTRUCT SAMPLE_ID ---\n",
    "    # Logic: {ImageID}__{TargetName}\n",
    "    print(\"Step 2: Constructing sample_id...\")\n",
    "    sub['sample_id'] = sub['image_id'] + \"__\" + sub['target_name']\n",
    "\n",
    "    # --- C. CLIP NEGATIVES ---\n",
    "    num_negatives = (sub[\"target\"] < 0).sum()\n",
    "    if num_negatives > 0:\n",
    "        print(f\"⚠️ WARNING: Found {num_negatives} negative predictions. Clipping to 0.\")\n",
    "        sub[\"target\"] = sub[\"target\"].clip(lower=0)\n",
    "\n",
    "    # --- D. FINALIZE ---\n",
    "    final_output = sub[['sample_id', 'target']].copy()\n",
    "\n",
    "    # Sort to be tidy (helps with debugging)\n",
    "    final_output = final_output.sort_values('sample_id')\n",
    "\n",
    "    # Safety Check: Do we have NaNs?\n",
    "    if final_output['target'].isna().any():\n",
    "        print(\"❌ CRITICAL: NaNs found in target. Filling with 0.\")\n",
    "        final_output['target'] = final_output['target'].fillna(0)\n",
    "\n",
    "    # --- E. SAVE ---\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    final_output.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"✅ Submission saved to: {output_path}\")\n",
    "    print(f\"   Shape: {final_output.shape}\")\n",
    "    print(f\"   Unique Targets: {sub['target_name'].unique()}\")\n",
    "    print(\"   Head:\")\n",
    "    print(final_output.head())\n",
    "\n",
    "    return final_output\n",
    "\n",
    "# --- EXECUTE ---\n",
    "try:\n",
    "    submission = generate_submission_direct(pred_long, SUBMISSION_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error generating submission: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256c892",
   "metadata": {
    "papermill": {
     "duration": 0.004317,
     "end_time": "2026-01-24T06:38:07.933066",
     "exception": false,
     "start_time": "2026-01-24T06:38:07.928749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. SANITY CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b03e9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:38:07.943225Z",
     "iopub.status.busy": "2026-01-24T06:38:07.942812Z",
     "iopub.status.idle": "2026-01-24T06:38:08.360168Z",
     "shell.execute_reply": "2026-01-24T06:38:08.359284Z"
    },
    "papermill": {
     "duration": 0.4241,
     "end_time": "2026-01-24T06:38:08.361599",
     "exception": false,
     "start_time": "2026-01-24T06:38:07.937499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "SANITY CHECKS (End-to-End: data -> transforms -> extractor forward -> 3-target -> reconstruct -> 5-target)\n",
      "====================\n",
      "[CELL4] Dataset init: 4 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/train/ID1011485656.jpg\n",
      "[Sanity] image batch tensor shape: (4, 3, 224, 224)\n",
      "[Sanity] image batch tensor dtype : torch.float32\n",
      "[Sanity] y_true_5 shape: (4, 5)\n",
      "[Sanity] y_true_5 dtype: float32\n",
      "[Sanity] y_pred_3 shape: (4, 3)\n",
      "[Sanity] y_pred_3 dtype: float32\n",
      "[Sanity] y_pred_5 shape: (4, 5)\n",
      "[Sanity] y_pred_5 dtype: float32\n",
      "\n",
      "✅ Sanity checks passed (no exceptions).\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Sanity checks\n",
    "# ============================================\n",
    "print(\"\\n====================\")\n",
    "print(\"SANITY CHECKS (End-to-End: data -> transforms -> extractor forward -> 3-target -> reconstruct -> 5-target)\")\n",
    "print(\"====================\")\n",
    "\n",
    "try:\n",
    "    # Choose a small batch from TRAIN (y_true available)\n",
    "    if len(train_wide) == 0:\n",
    "        raise ValueError(\"train_wide is empty; cannot run sanity checks with y_true.\")\n",
    "\n",
    "    B = min(4, len(train_wide))\n",
    "    sample_paths = train_wide[\"abs_path\"].iloc[:B].tolist()\n",
    "\n",
    "    # Build image batch via the same transform pipeline (resize-only)\n",
    "    ds_sc = ImagePathDataset(sample_paths, transform=IMG_TFM)\n",
    "    dl_sc = DataLoader(\n",
    "        ds_sc,\n",
    "        batch_size=B,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=(DEVICE == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    x = next(iter(dl_sc))  # [B, 3, IMG_SIZE, IMG_SIZE]\n",
    "    print(\"[Sanity] image batch tensor shape:\", tuple(x.shape))\n",
    "    print(\"[Sanity] image batch tensor dtype :\", x.dtype)\n",
    "\n",
    "    # y_true (5 targets) from train_wide if available\n",
    "    y_true_5 = train_wide[SUBMISSION_TARGET_NAMES].iloc[:B].values.astype(np.float32)\n",
    "    print(\"[Sanity] y_true_5 shape:\", y_true_5.shape)\n",
    "    print(\"[Sanity] y_true_5 dtype:\", y_true_5.dtype)\n",
    "\n",
    "    # Model forward (EXTRACTOR) -> features\n",
    "    with torch.no_grad():\n",
    "        x_dev = x.to(DEVICE, non_blocking=True)\n",
    "        feats = EXTRACTOR(x_dev).view(x_dev.size(0), -1)  # [B, 512]\n",
    "    feats_np = feats.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # 3-target output from RFs\n",
    "    y_pred_3 = np.zeros((B, len(CORE_TARGET_NAMES)), dtype=np.float32)\n",
    "    for j, t in enumerate(CORE_TARGET_NAMES):\n",
    "        y_pred_3[:, j] = models_rf[t].predict(feats_np).astype(np.float32)\n",
    "\n",
    "    print(\"[Sanity] y_pred_3 shape:\", y_pred_3.shape)\n",
    "    print(\"[Sanity] y_pred_3 dtype:\", y_pred_3.dtype)\n",
    "\n",
    "    # Reconstruct to 5 targets (LB-0-57 logic)\n",
    "    pred_total = np.maximum(0, y_pred_3[:, CORE_TARGET_NAMES.index(\"Dry_Total_g\")]).astype(np.float32)\n",
    "    pred_gdm   = np.maximum(0, y_pred_3[:, CORE_TARGET_NAMES.index(\"GDM_g\")]).astype(np.float32)\n",
    "    pred_green = np.maximum(0, y_pred_3[:, CORE_TARGET_NAMES.index(\"Dry_Green_g\")]).astype(np.float32)\n",
    "\n",
    "    pred_clover = np.maximum(0, pred_gdm - pred_green).astype(np.float32)\n",
    "    pred_dead   = np.maximum(0, pred_total - pred_gdm).astype(np.float32)\n",
    "\n",
    "    y_pred_5 = np.stack([pred_green, pred_dead, pred_clover, pred_gdm, pred_total], axis=1).astype(np.float32)\n",
    "\n",
    "    print(\"[Sanity] y_pred_5 shape:\", y_pred_5.shape)\n",
    "    print(\"[Sanity] y_pred_5 dtype:\", y_pred_5.dtype)\n",
    "\n",
    "    # Confirm fixed tensor shape requirement\n",
    "    assert tuple(x.shape[1:]) == (3, IMG_SIZE, IMG_SIZE), \"Unexpected image tensor shape after transforms.\"\n",
    "\n",
    "    print(\"\\n✅ Sanity checks passed (no exceptions).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n❌ Sanity checks failed with exception:\")\n",
    "    print(type(e).__name__, str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011bcbd",
   "metadata": {
    "papermill": {
     "duration": 0.004382,
     "end_time": "2026-01-24T06:38:08.370768",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.366386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492b985",
   "metadata": {
    "papermill": {
     "duration": 0.004524,
     "end_time": "2026-01-24T06:38:08.379998",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.375474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Change log\n",
    "\n",
    "## Modified cells\n",
    "- **Cell 2 (Letterboxing REMOVED)**\n",
    "  - Removed/disabled letterboxing behavior (no pad-to-square, no keep-aspect-ratio + pad).\n",
    "- **Cells 3–4 (ResNet18 feature extractor transforms)**\n",
    "  - Replaced `SquarePad() + Resize(...)` with **resize-only**: `Resize((IMG_SIZE, IMG_SIZE))`, keeping `ToTensor()` and `Normalize(...)` unchanged.\n",
    "- **Cell 5 (TTA transforms)**\n",
    "  - Replaced padding-based preprocessing with **resize-only** in all TTA views (original / hflip / vflip).\n",
    "- **Cells 6–11 (Core Strategy integration)**\n",
    "  - Implemented **3-target training** (`Dry_Total_g`, `GDM_g`, `Dry_Green_g`) via `CORE_TARGET_NAMES`.\n",
    "  - During inference, reconstructed the remaining 2 targets using LB-0-57 logic:\n",
    "    - `Dry_Clover_g = max(0, GDM_g - Dry_Green_g)`\n",
    "    - `Dry_Dead_g   = max(0, Dry_Total_g - GDM_g)`\n",
    "  - Ensured submission still outputs **all 5 targets** with correct target names.\n",
    "\n",
    "## Added/required cells\n",
    "- **Cell 12 (Sanity checks)**\n",
    "  - Runs one batch end-to-end:\n",
    "    - data → transforms → extractor forward → 3-target RF prediction → reconstruction → 5-target output\n",
    "  - Prints shapes/dtypes and asserts the image tensor shape is `[B, 3, IMG_SIZE, IMG_SIZE]`.\n",
    "\n",
    "## Letterboxing removal locations\n",
    "- Removed from:\n",
    "  - Feature extractor pipeline (Cells 3–4)\n",
    "  - TTA pipelines (Cell 5)\n",
    "- Replaced everywhere with:\n",
    "  - `Resize((IMG_SIZE, IMG_SIZE))` only (no padding, no cropping)\n",
    "\n",
    "## Assumptions (explicit)\n",
    "- Notebook A did not define a reusable image size variable, so **`IMG_SIZE = 224`** was introduced once (Cell 1) and used everywhere.\n",
    "- Submission IDs are constructed from filenames as `image_id__target_name`, consistent with Notebook A’s existing submission logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb97d3d",
   "metadata": {
    "papermill": {
     "duration": 0.004294,
     "end_time": "2026-01-24T06:38:08.388864",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.384570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275432a4",
   "metadata": {
    "papermill": {
     "duration": 0.00436,
     "end_time": "2026-01-24T06:38:08.397597",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.393237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. EXPORT AUGMENTED IMAGES SO THAT CHU NHAT CAN FIND BEST PARAMETERS FOR RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19a7195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:38:08.407832Z",
     "iopub.status.busy": "2026-01-24T06:38:08.407549Z",
     "iopub.status.idle": "2026-01-24T06:38:08.412270Z",
     "shell.execute_reply": "2026-01-24T06:38:08.411727Z"
    },
    "papermill": {
     "duration": 0.01161,
     "end_time": "2026-01-24T06:38:08.413546",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.401936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================\n",
    "# #  Export augmented TRAIN images (original / hflip / vflip) WITHOUT resizing\n",
    "# # + Print sizes for a sample (original vs hflip vs vflip)\n",
    "# # Writes to: /kaggle/working/augmented_train_images/{original,hflip,vflip}/\n",
    "# # ============================================\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# from torchvision import transforms\n",
    "\n",
    "# # ---- Config ----\n",
    "# OUTPUT_DIR = Path(\"/kaggle/working/augmented_train_images\")  # ✅ matches zipping cell\n",
    "# MAX_IMAGES = None          # set to an int (e.g., 500) to limit exports; None = export all\n",
    "# PRINT_FIRST_N = 10         # how many images to print size diagnostics for\n",
    "\n",
    "# # ---- Force training image source ----\n",
    "# if \"train_wide\" in globals() and \"abs_path\" in train_wide.columns and len(train_wide) > 0:\n",
    "#     export_abs_paths = train_wide[\"abs_path\"].tolist()\n",
    "#     export_rel_paths = train_wide[\"image_path\"].tolist()\n",
    "#     print(f\"[Export] Using TRAIN images: {len(export_abs_paths)}\")\n",
    "# else:\n",
    "#     raise RuntimeError(\n",
    "#         \"train_wide['abs_path'] not found. Run the cell that builds train_wide and its abs_path first.\"\n",
    "#     )\n",
    "\n",
    "# # Apply MAX_IMAGES cap (optional)\n",
    "# if isinstance(MAX_IMAGES, int) and MAX_IMAGES > 0:\n",
    "#     export_abs_paths = export_abs_paths[:MAX_IMAGES]\n",
    "#     export_rel_paths = export_rel_paths[:MAX_IMAGES]\n",
    "#     print(f\"[Export] Capped to MAX_IMAGES={MAX_IMAGES}\")\n",
    "\n",
    "# # ---- Save-friendly augmentation pipelines (PIL outputs; NO Normalize/ToTensor; NO padding; NO resizing) ----\n",
    "# # Goal: keep image sizes exactly as original.\n",
    "# save_views = {\n",
    "#     \"original\": transforms.Compose([]),  # identity\n",
    "#     \"hflip\": transforms.Compose([transforms.RandomHorizontalFlip(p=1.0)]),\n",
    "#     \"vflip\": transforms.Compose([transforms.RandomVerticalFlip(p=1.0)]),\n",
    "# }\n",
    "\n",
    "# # ---- Create output folders ----\n",
    "# OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# for view_name in save_views.keys():\n",
    "#     (OUTPUT_DIR / view_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# print(f\"[Export] Writing augmented TRAIN images (no resize) to: {OUTPUT_DIR}\")\n",
    "\n",
    "# # ---- Export loop + size diagnostics ----\n",
    "# n_ok, n_fail = 0, 0\n",
    "# printed = 0\n",
    "\n",
    "# for i, (abs_p, rel_p) in enumerate(zip(export_abs_paths, export_rel_paths), start=1):\n",
    "#     try:\n",
    "#         img = Image.open(abs_p).convert(\"RGB\")\n",
    "#         orig_size = img.size  # (W, H)\n",
    "\n",
    "#         base_name = Path(rel_p).name\n",
    "#         stem = Path(base_name).stem\n",
    "#         ext = Path(base_name).suffix.lower()\n",
    "#         if ext not in {\".jpg\", \".jpeg\", \".png\"}:\n",
    "#             ext = \".jpg\"\n",
    "\n",
    "#         sizes = {\"original\": None, \"hflip\": None, \"vflip\": None}\n",
    "\n",
    "#         for view_name, tfm in save_views.items():\n",
    "#             out_img = tfm(img)\n",
    "#             sizes[view_name] = out_img.size  # (W, H)\n",
    "#             out_path = OUTPUT_DIR / view_name / f\"{stem}__{view_name}{ext}\"\n",
    "\n",
    "#             # Save with appropriate settings (avoid passing invalid args for PNG)\n",
    "#             if ext in {\".jpg\", \".jpeg\"}:\n",
    "#                 out_img.save(out_path, quality=95)\n",
    "#             else:\n",
    "#                 out_img.save(out_path)\n",
    "\n",
    "#         # Print size diagnostics for first PRINT_FIRST_N images\n",
    "#         if printed < PRINT_FIRST_N:\n",
    "#             print(f\"\\n[Size] {i}: {base_name}\")\n",
    "#             print(f\"  - original: {orig_size}\")\n",
    "#             print(f\"  - hflip   : {sizes['hflip']}\")\n",
    "#             print(f\"  - vflip   : {sizes['vflip']}\")\n",
    "#             printed += 1\n",
    "\n",
    "#         # Hard check: sizes must match\n",
    "#         if not (orig_size == sizes[\"hflip\"] == sizes[\"vflip\"]):\n",
    "#             print(f\"[WARN] Size mismatch for {base_name}: orig={orig_size}, hflip={sizes['hflip']}, vflip={sizes['vflip']}\")\n",
    "\n",
    "#         n_ok += 1\n",
    "#         if i == 1 or i % 200 == 0 or i == len(export_abs_paths):\n",
    "#             print(f\"[Export] {i}/{len(export_abs_paths)} done\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         n_fail += 1\n",
    "#         if n_fail <= 10:\n",
    "#             print(f\"[Export][WARN] Failed on: {abs_p} | {type(e).__name__}: {e}\")\n",
    "\n",
    "# print(f\"\\n[Export] Completed. Success={n_ok}, Failed={n_fail}\")\n",
    "# print(f\"[Export] Output folder: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e6a70",
   "metadata": {
    "papermill": {
     "duration": 0.004438,
     "end_time": "2026-01-24T06:38:08.422452",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.418014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11 DOWNLOAD OUTPUT AUGMENTED IMAGES BY USING SHUTIL LIBRARY IN PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d41849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T06:38:08.432487Z",
     "iopub.status.busy": "2026-01-24T06:38:08.432051Z",
     "iopub.status.idle": "2026-01-24T06:38:08.435337Z",
     "shell.execute_reply": "2026-01-24T06:38:08.434687Z"
    },
    "papermill": {
     "duration": 0.00989,
     "end_time": "2026-01-24T06:38:08.436699",
     "exception": false,
     "start_time": "2026-01-24T06:38:08.426809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================\n",
    "# # Zip the exported folder from CODE CELL 1\n",
    "# # (Smooth transition: uses the SAME directory path)\n",
    "# # ============================================\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Define the directory you want to zip (the augmented TRAIN images folder created above)\n",
    "# directory_to_zip = str(OUTPUT_DIR)  # ✅ directly reuses OUTPUT_DIR from Cell 1\n",
    "\n",
    "# # Define the output filename (without extension)\n",
    "# output_filename = 'augmented_train_images_archive'\n",
    "\n",
    "# # Create the zip archive\n",
    "# shutil.make_archive(output_filename, 'zip', directory_to_zip)\n",
    "\n",
    "# print(f\"Archived {directory_to_zip} to {output_filename}.zip\")\n",
    "# print(\"✅ Zip saved at:\", os.path.join(\"/kaggle/working\", f\"{output_filename}.zip\"))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 2847,
     "sourceId": 4958,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.228049,
   "end_time": "2026-01-24T06:38:10.776072",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-24T06:36:20.548023",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
