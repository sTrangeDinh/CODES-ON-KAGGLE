{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8e913c",
   "metadata": {
    "papermill": {
     "duration": 0.00614,
     "end_time": "2026-01-23T05:11:11.800126",
     "exception": false,
     "start_time": "2026-01-23T05:11:11.793986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. IMPORT LIBARIES + PATHS + REPRODUCBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f059e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:11.812079Z",
     "iopub.status.busy": "2026-01-23T05:11:11.811735Z",
     "iopub.status.idle": "2026-01-23T05:11:28.676775Z",
     "shell.execute_reply": "2026-01-23T05:11:28.675732Z"
    },
    "papermill": {
     "duration": 16.873575,
     "end_time": "2026-01-23T05:11:28.678900",
     "exception": false,
     "start_time": "2026-01-23T05:11:11.805325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DATA_DIR: /kaggle/input/csiro-biomass\n",
      "✅ WEIGHTS_DIR: /kaggle/input/pretrained-pytorch-models\n",
      "✅ DEVICE: cpu\n",
      "✅ Train CSV: /kaggle/input/csiro-biomass/train.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1 — Imports + Paths + Reprocibility\n",
    "# ============================================\n",
    "\"\"\"\n",
    "Kaggle to GitHub Sync Configuration\n",
    "Repository: CODES-ON-KAGGLE\n",
    "\"\"\"\n",
    "# Import\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ✅ Competition directory (as you stated)\n",
    "DATA_DIR = \"/kaggle/input/csiro-biomass\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "# SAMPLE_SUB_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# ✅ Pretrained weights dataset input for model resnet18\n",
    "WEIGHTS_DIR = \"/kaggle/input/pretrained-pytorch-models\"\n",
    "\n",
    "# Inference\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# BATCH_SIZE = 1 # INCREASE BATCH SIZE WHEN INFERENCE\n",
    "# NUM_WORKERS = 1 # 2 IN MY PRIOR DELETED VERSION\n",
    "# N_FOLDS = 5 \n",
    "\n",
    "# Safety checks (fail fast if something isn't mounted)\n",
    "for p in [DATA_DIR, WEIGHTS_DIR, TRAIN_CSV, TEST_CSV]:\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Missing expected path: {p}\")\n",
    "\n",
    "print(\"✅ DATA_DIR:\", DATA_DIR)\n",
    "print(\"✅ WEIGHTS_DIR:\", WEIGHTS_DIR)\n",
    "print(\"✅ DEVICE:\", DEVICE)\n",
    "print(\"✅ Train CSV:\", TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366b2fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:28.691566Z",
     "iopub.status.busy": "2026-01-23T05:11:28.690432Z",
     "iopub.status.idle": "2026-01-23T05:11:28.697564Z",
     "shell.execute_reply": "2026-01-23T05:11:28.696317Z"
    },
    "papermill": {
     "duration": 0.015877,
     "end_time": "2026-01-23T05:11:28.699849",
     "exception": false,
     "start_time": "2026-01-23T05:11:28.683972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1.5 — Letterboxing\n",
    "# ============================================\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        max_wh = max(w, h)\n",
    "        p_left, p_top = (max_wh - w) // 2, (max_wh - h) // 2\n",
    "        p_right, p_bottom = max_wh - w - p_left, max_wh - h - p_top\n",
    "        return F.pad(image, (p_left, p_top, p_right, p_bottom), 0, 'constant') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89925500",
   "metadata": {
    "papermill": {
     "duration": 0.004944,
     "end_time": "2026-01-23T05:11:28.709831",
     "exception": false,
     "start_time": "2026-01-23T05:11:28.704887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. SETUP WEIGHTS FOR THE OFFLINE RESNET 18\n",
    "Since we run code when the Internet is off, we have to manually input a dataset on Kaggle\n",
    "that contains ResNet18 ImageNet weights.\n",
    "The ResNet18 ImageNet weights will be named resnet18-5c106cde.pth or resnet18.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e954cd9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:28.721759Z",
     "iopub.status.busy": "2026-01-23T05:11:28.721399Z",
     "iopub.status.idle": "2026-01-23T05:11:30.140488Z",
     "shell.execute_reply": "2026-01-23T05:11:30.139091Z"
    },
    "papermill": {
     "duration": 1.428352,
     "end_time": "2026-01-23T05:11:30.143118",
     "exception": false,
     "start_time": "2026-01-23T05:11:28.714766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] weights_dir: /kaggle/input/pretrained-pytorch-models\n",
      "[DEBUG] resnet18 candidates found: 1\n",
      "[DEBUG] first few candidates: ['/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth']\n",
      "[DEBUG] RESNET18_WEIGHTS selected: /kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth\n",
      "[DEBUG] Feature extractor ready.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2 — Model / Weights Setup (ResNet18 offline) + Robust Loader + Debug Prints\n",
    "# ============================================\n",
    "def find_resnet18_weights(weights_dir: str) -> str:\n",
    "    print(\"[DEBUG] weights_dir:\", weights_dir)\n",
    "\n",
    "    wd = Path(weights_dir)\n",
    "    if not wd.exists():\n",
    "        raise FileNotFoundError(f\"Missing weights dataset. Expected directory: {weights_dir}\")\n",
    "\n",
    "    candidates = []\n",
    "    for p in wd.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in {\".pth\", \".pt\"} and \"resnet18\" in p.name.lower():\n",
    "            candidates.append(str(p))\n",
    "\n",
    "    print(\"[DEBUG] resnet18 candidates found:\", len(candidates))\n",
    "    if candidates:\n",
    "        print(\"[DEBUG] first few candidates:\", candidates[:5])\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No resnet18 .pth/.pt file found under {weights_dir}\")\n",
    "\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: (0 if re.search(r\"resnet18-.*\\.pth$\", os.path.basename(x).lower()) else 1, len(x))\n",
    "    )\n",
    "    chosen = candidates_sorted[0]\n",
    "    print(\"[DEBUG] RESNET18_WEIGHTS selected:\", chosen)\n",
    "    return chosen\n",
    "\n",
    "RESNET18_WEIGHTS = find_resnet18_weights(WEIGHTS_DIR)\n",
    "\n",
    "def _to_state_dict(obj):\n",
    "    \"\"\"Convert various checkpoint formats into a state_dict dict.\"\"\"\n",
    "    if isinstance(obj, nn.Module):\n",
    "        return obj.state_dict()\n",
    "    if isinstance(obj, dict):\n",
    "        if \"state_dict\" in obj and isinstance(obj[\"state_dict\"], dict):\n",
    "            return obj[\"state_dict\"]\n",
    "        # If it already looks like a state_dict\n",
    "        if all(isinstance(k, str) for k in obj.keys()):\n",
    "            return obj\n",
    "    raise TypeError(f\"Unsupported checkpoint type: {type(obj)}\")\n",
    "\n",
    "def build_resnet18_feature_extractor(weights_path: str, device: str):\n",
    "    model = models.resnet18(weights=None)  # no internet download\n",
    "    raw = torch.load(weights_path, map_location=\"cpu\", weights_only=False)\n",
    "    state = _to_state_dict(raw)\n",
    "\n",
    "    cleaned = {}\n",
    "    for k, v in state.items():\n",
    "        k2 = k\n",
    "        for prefix in (\"module.\", \"model.\"):\n",
    "            if k2.startswith(prefix):\n",
    "                k2 = k2[len(prefix):]\n",
    "        cleaned[k2] = v\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
    "    if missing:\n",
    "        print(\"Warning: missing keys when loading weights:\", missing[:5], (\"...\" if len(missing) > 5 else \"\"))\n",
    "    if unexpected:\n",
    "        print(\"Warning: unexpected keys when loading weights:\", unexpected[:5], (\"...\" if len(unexpected) > 5 else \"\"))\n",
    "\n",
    "    extractor = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "    extractor.eval()\n",
    "    for p in extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    tfm = transforms.Compose([\n",
    "        SquarePad(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ])\n",
    "    return extractor, tfm\n",
    "\n",
    "EXTRACTOR, IMG_TFM = build_resnet18_feature_extractor(RESNET18_WEIGHTS, DEVICE)\n",
    "print(\"[DEBUG] Feature extractor ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d352b",
   "metadata": {
    "papermill": {
     "duration": 0.005035,
     "end_time": "2026-01-23T05:11:30.153505",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.148470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ed115c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:30.165401Z",
     "iopub.status.busy": "2026-01-23T05:11:30.164960Z",
     "iopub.status.idle": "2026-01-23T05:11:30.531488Z",
     "shell.execute_reply": "2026-01-23T05:11:30.530012Z"
    },
    "papermill": {
     "duration": 0.375365,
     "end_time": "2026-01-23T05:11:30.533794",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.158429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] weights_dir: /kaggle/input/pretrained-pytorch-models\n",
      "[DEBUG] resnet18 candidates found: 1\n",
      "[DEBUG] first few candidates: ['/kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth']\n",
      "[DEBUG] RESNET18_WEIGHTS selected: /kaggle/input/pretrained-pytorch-models/resnet18-5c106cde.pth\n",
      "[DEBUG] Feature extractor ready.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2 — Model / Weights Setup (ResNet18 offline) + Robust Loader + Debug Prints\n",
    "# ============================================\n",
    "def find_resnet18_weights(weights_dir: str) -> str:\n",
    "    print(\"[DEBUG] weights_dir:\", weights_dir)\n",
    "\n",
    "    wd = Path(weights_dir)\n",
    "    if not wd.exists():\n",
    "        raise FileNotFoundError(f\"Missing weights dataset. Expected directory: {weights_dir}\")\n",
    "\n",
    "    candidates = []\n",
    "    for p in wd.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in {\".pth\", \".pt\"} and \"resnet18\" in p.name.lower():\n",
    "            candidates.append(str(p))\n",
    "\n",
    "    print(\"[DEBUG] resnet18 candidates found:\", len(candidates))\n",
    "    if candidates:\n",
    "        print(\"[DEBUG] first few candidates:\", candidates[:5])\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No resnet18 .pth/.pt file found under {weights_dir}\")\n",
    "\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: (0 if re.search(r\"resnet18-.*\\.pth$\", os.path.basename(x).lower()) else 1, len(x))\n",
    "    )\n",
    "    chosen = candidates_sorted[0]\n",
    "    print(\"[DEBUG] RESNET18_WEIGHTS selected:\", chosen)\n",
    "    return chosen\n",
    "\n",
    "RESNET18_WEIGHTS = find_resnet18_weights(WEIGHTS_DIR)\n",
    "\n",
    "def _to_state_dict(obj):\n",
    "    \"\"\"Convert various checkpoint formats into a state_dict dict.\"\"\"\n",
    "    if isinstance(obj, nn.Module):\n",
    "        return obj.state_dict()\n",
    "    if isinstance(obj, dict):\n",
    "        if \"state_dict\" in obj and isinstance(obj[\"state_dict\"], dict):\n",
    "            return obj[\"state_dict\"]\n",
    "        # If it already looks like a state_dict\n",
    "        if all(isinstance(k, str) for k in obj.keys()):\n",
    "            return obj\n",
    "    raise TypeError(f\"Unsupported checkpoint type: {type(obj)}\")\n",
    "\n",
    "def build_resnet18_feature_extractor(weights_path: str, device: str):\n",
    "    model = models.resnet18(weights=None)  # no internet download\n",
    "    raw = torch.load(weights_path, map_location=\"cpu\", weights_only=False)\n",
    "    state = _to_state_dict(raw)\n",
    "\n",
    "    cleaned = {}\n",
    "    for k, v in state.items():\n",
    "        k2 = k\n",
    "        for prefix in (\"module.\", \"model.\"):\n",
    "            if k2.startswith(prefix):\n",
    "                k2 = k2[len(prefix):]\n",
    "        cleaned[k2] = v\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(cleaned, strict=False)\n",
    "    if missing:\n",
    "        print(\"Warning: missing keys when loading weights:\", missing[:5], (\"...\" if len(missing) > 5 else \"\"))\n",
    "    if unexpected:\n",
    "        print(\"Warning: unexpected keys when loading weights:\", unexpected[:5], (\"...\" if len(unexpected) > 5 else \"\"))\n",
    "\n",
    "    extractor = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "    extractor.eval()\n",
    "    for p in extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    tfm = transforms.Compose([\n",
    "        SquarePad(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ])\n",
    "    return extractor, tfm\n",
    "\n",
    "EXTRACTOR, IMG_TFM = build_resnet18_feature_extractor(RESNET18_WEIGHTS, DEVICE)\n",
    "print(\"[DEBUG] Feature extractor ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39076c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:30.546317Z",
     "iopub.status.busy": "2026-01-23T05:11:30.545922Z",
     "iopub.status.idle": "2026-01-23T05:11:30.554062Z",
     "shell.execute_reply": "2026-01-23T05:11:30.552846Z"
    },
    "papermill": {
     "duration": 0.017193,
     "end_time": "2026-01-23T05:11:30.556418",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.539225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Defined get_tta_transforms() for validation/inference-only TTA.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2.5 — AUGMENTATIONS — TTA Views\n",
    "# (Integrated from LB-0-57-CODE section \"2. AUGMENTATIONS ( CHI DUNG VALIDATION)\")\n",
    "# ============================================\n",
    "def get_tta_transforms():\n",
    "    \"\"\"\n",
    "    Returns a LIST of torchvision transform pipelines for TTA.\n",
    "    Each pipeline is a different \"view\" of the image.\n",
    "    NOTE: Applied ONLY for validation/inference (not training), consistent with 'CHI DUNG VALIDATION'.\n",
    "    \"\"\"\n",
    "    # Base pipeline (Resize + Normalize + ToTensor) mirrors IMG_TFM normalization config.\n",
    "    base_transforms = [\n",
    "        SquarePad(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # View 1: Original (Resize + Normalize)\n",
    "    original_view = transforms.Compose([\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 2: Horizontal Flip (always)\n",
    "    hflip_view = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    # View 3: Vertical Flip (always)\n",
    "    vflip_view = transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(p=1.0),\n",
    "        *base_transforms\n",
    "    ])\n",
    "\n",
    "    return [original_view, hflip_view, vflip_view]\n",
    "\n",
    "print(\"✅ Defined get_tta_transforms() for validation/inference-only TTA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1b2800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:30.569711Z",
     "iopub.status.busy": "2026-01-23T05:11:30.569366Z",
     "iopub.status.idle": "2026-01-23T05:11:30.654399Z",
     "shell.execute_reply": "2026-01-23T05:11:30.653290Z"
    },
    "papermill": {
     "duration": 0.094471,
     "end_time": "2026-01-23T05:11:30.656427",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.561956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory for ground truth: /kaggle/input/csiro-biomass/test\n",
      "✅ Found 1 images in directory.\n",
      "train_df: (1785, 9)\n",
      "train_wide: (357, 7)\n",
      "[DEBUG] train_df columns: ['sample_id', 'image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm', 'target_name', 'target']\n",
      "[DEBUG] train_wide rows : 357\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3 — Data Loading (train/test/sample_submission)\n",
    "# ============================================\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "TEST_FOLDER_NAME = \"test\"\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, TEST_FOLDER_NAME)\n",
    "\n",
    "print(f\"Scanning directory for ground truth: {TEST_IMG_DIR}\")\n",
    "\n",
    "# 3. MANUAL DIRECTORY SCAN\n",
    "# We ignore the provided test.csv and look at the disk\n",
    "try:\n",
    "    # Get all image files sorted alphabetically\n",
    "    all_test_images = sorted([\n",
    "        f for f in os.listdir(TEST_IMG_DIR) \n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ WARN: Test directory not found (Local run?). Creating empty DF.\")\n",
    "    all_test_images = []\n",
    "\n",
    "print(f\"✅ Found {len(all_test_images)} images in directory.\")\n",
    "\n",
    "# 4. CONSTRUCT COMPATIBLE DATAFRAME\n",
    "# Trang's code later does: os.path.join(DATA_DIR, p)\n",
    "# So we must ensure 'p' includes the folder name, e.g., \"test/image_01.jpg\"\n",
    "\n",
    "data = []\n",
    "for filename in all_test_images:\n",
    "    # Create the relative path so Trang's join works\n",
    "    relative_path = os.path.join(TEST_FOLDER_NAME, filename)\n",
    "    \n",
    "    data.append({\n",
    "        \"image_path\": relative_path,  # This fixes the pathing\n",
    "        \"sample_id\": filename,        # Placeholder\n",
    "        \"target_name\": \"GDM\"          # Placeholder\n",
    "    })\n",
    "\n",
    "# Overwrite test_df with our manual list\n",
    "test_df = pd.DataFrame(data)\n",
    "\n",
    "# 5. Sample Sub (Optional)\n",
    "# if os.path.exists(SAMPLE_SUB_CSV):\n",
    "    # sample_sub = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "# else:\n",
    "    # sample_sub = pd.DataFrame()\n",
    "\n",
    "\n",
    "#test_df  = pd.read_csv(TEST_CSV)\n",
    "#sample_sub = pd.read_csv(SAMPLE_SUB_CSV)\n",
    "\n",
    "print(\"train_df:\", train_df.shape)\n",
    "#print(\"test_df :\", test_df.shape)\n",
    "#print(\"sample_submission:\", sample_sub.shape)\n",
    "\n",
    "TARGET_NAMES = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
    "\n",
    "def make_train_wide(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      image_path + TARGET_NAMES columns\n",
    "    Supports:\n",
    "      - modern long format: image_path, target_name, target\n",
    "      - fallback: image_path, target (assumes 5-row blocks per image)\n",
    "    \"\"\"\n",
    "    if {\"image_path\", \"target_name\", \"target\"}.issubset(df.columns):\n",
    "        wide = (\n",
    "            df.pivot_table(index=\"image_path\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "              .reset_index()\n",
    "        )\n",
    "        for t in TARGET_NAMES:\n",
    "            if t not in wide.columns:\n",
    "                wide[t] = np.nan\n",
    "        return wide[[\"image_path\"] + TARGET_NAMES]\n",
    "\n",
    "    if {\"image_path\", \"target\"}.issubset(df.columns):\n",
    "        paths = df[\"image_path\"].values\n",
    "        y = df[\"target\"].values\n",
    "        if len(df) % 5 != 0:\n",
    "            raise ValueError(\"Fallback parsing expected train rows multiple of 5.\")\n",
    "        unique_paths = paths[0::5]\n",
    "        wide = pd.DataFrame({\"image_path\": unique_paths})\n",
    "        for i, t in enumerate(TARGET_NAMES):\n",
    "            wide[t] = y[i::5]\n",
    "        return wide\n",
    "\n",
    "    raise ValueError(\"train.csv must have either (image_path,target_name,target) or (image_path,target).\")\n",
    "\n",
    "train_wide = make_train_wide(train_df)\n",
    "train_wide[\"abs_path\"] = train_wide[\"image_path\"].apply(lambda p: os.path.join(DATA_DIR, p))\n",
    "train_wide = train_wide.dropna(subset=TARGET_NAMES).reset_index(drop=True)\n",
    "\n",
    "print(\"train_wide:\", train_wide.shape)\n",
    "train_wide.head()\n",
    "# Fail-fast checks (put after train_wide is built)\n",
    "print(\"[DEBUG] train_df columns:\", list(train_df.columns))\n",
    "#print(\"[DEBUG] test_df columns :\", list(test_df.columns))\n",
    "print(\"[DEBUG] train_wide rows :\", len(train_wide))\n",
    "\n",
    "if len(train_wide) == 0:\n",
    "    raise ValueError(\"train_wide is empty. train.csv parsing likely mismatched the actual format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7562a",
   "metadata": {
    "papermill": {
     "duration": 0.005183,
     "end_time": "2026-01-23T05:11:30.666840",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.661657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. SET UP A CLASS OF RESNET18 FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ea2516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:30.679700Z",
     "iopub.status.busy": "2026-01-23T05:11:30.678645Z",
     "iopub.status.idle": "2026-01-23T05:11:30.692059Z",
     "shell.execute_reply": "2026-01-23T05:11:30.690927Z"
    },
    "papermill": {
     "duration": 0.022131,
     "end_time": "2026-01-23T05:11:30.694237",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.672106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4 — Feature Extraction Utilities (stable for Kaggle submission)\n",
    "# ============================================\n",
    "BATCH_SIZE = 2  # keep your setting\n",
    "\n",
    "NUM_WORKERS = 0  # ✅ stable setting for Kaggle submission runs\n",
    "\n",
    "class ImagePathDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f\"[CELL4] Dataset init: {len(self.image_paths)} images\")\n",
    "        if self.image_paths:\n",
    "            print(\"[CELL4] Example path:\", self.image_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            if idx < 3:\n",
    "                print(f\"[CELL4][WARN] Open failed idx={idx}: {p} | {type(e).__name__}\")\n",
    "            img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(image_paths, batch_size=BATCH_SIZE, transform=IMG_TFM):\n",
    "    print(f\"[CELL4] extract_features: {len(image_paths)} images | batch_size={batch_size} | workers={NUM_WORKERS}\")\n",
    "\n",
    "    ds = ImagePathDataset(image_paths, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,           # ✅ stable\n",
    "        pin_memory=(DEVICE == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    feats = []\n",
    "    total_batches = len(loader)\n",
    "    print(f\"[CELL4] total_batches={total_batches}\")\n",
    "\n",
    "    for b_idx, batch in enumerate(loader):\n",
    "        if b_idx == 0:\n",
    "            print(\"[CELL4] First batch:\", tuple(batch.shape))\n",
    "\n",
    "        batch = batch.to(DEVICE, non_blocking=True)\n",
    "        out = EXTRACTOR(batch)              # [B, 512, 1, 1]\n",
    "        out = out.view(out.size(0), -1)     # [B, 512]\n",
    "        feats.append(out.cpu().numpy())\n",
    "\n",
    "        if (b_idx + 1) == 1 or (b_idx + 1) == total_batches or (b_idx + 1) % max(1, total_batches // 5) == 0:\n",
    "            print(f\"[CELL4] Progress: {b_idx+1}/{total_batches}\")\n",
    "\n",
    "    feats_np = np.vstack(feats) if feats else np.empty((0, 512), dtype=np.float32)\n",
    "    print(\"[CELL4] features shape:\", feats_np.shape)\n",
    "    return feats_np#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60b462",
   "metadata": {
    "papermill": {
     "duration": 0.005574,
     "end_time": "2026-01-23T05:11:30.705326",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.699752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Extract Train Images Features + Make sure the function in Cell 4 runs correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51163d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:11:30.718822Z",
     "iopub.status.busy": "2026-01-23T05:11:30.718036Z",
     "iopub.status.idle": "2026-01-23T05:12:24.004526Z",
     "shell.execute_reply": "2026-01-23T05:12:24.003271Z"
    },
    "papermill": {
     "duration": 53.295322,
     "end_time": "2026-01-23T05:12:24.006792",
     "exception": false,
     "start_time": "2026-01-23T05:11:30.711470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL4] extract_features: 357 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 357 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/train/ID1011485656.jpg\n",
      "[CELL4] total_batches=23\n",
      "[CELL4] First batch: (16, 3, 224, 224)\n",
      "[CELL4] Progress: 1/23\n",
      "[CELL4] Progress: 4/23\n",
      "[CELL4] Progress: 8/23\n",
      "[CELL4] Progress: 12/23\n",
      "[CELL4] Progress: 16/23\n",
      "[CELL4] Progress: 20/23\n",
      "[CELL4] Progress: 23/23\n",
      "[CELL4] features shape: (357, 512)\n",
      "X_train: (357, 512)\n",
      "Y_train: (357, 5)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5 — Extract Train Features\n",
    "# ============================================\n",
    "X_train = extract_features(train_wide[\"abs_path\"].tolist(), batch_size=16)\n",
    "Y_train = train_wide[TARGET_NAMES].values.astype(np.float32)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"Y_train:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84876217",
   "metadata": {
    "papermill": {
     "duration": 0.006005,
     "end_time": "2026-01-23T05:12:24.019004",
     "exception": false,
     "start_time": "2026-01-23T05:12:24.012999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Train 5 Random Regression Models, 1 Random Forest per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70717dfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:12:24.033105Z",
     "iopub.status.busy": "2026-01-23T05:12:24.032758Z",
     "iopub.status.idle": "2026-01-23T05:14:50.924388Z",
     "shell.execute_reply": "2026-01-23T05:14:50.923185Z"
    },
    "papermill": {
     "duration": 146.905781,
     "end_time": "2026-01-23T05:14:50.931071",
     "exception": false,
     "start_time": "2026-01-23T05:12:24.025290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained RF models: ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6 — Training (one RandomForest per target)\n",
    "# ============================================\n",
    "models_rf = {}\n",
    "\n",
    "for i, t in enumerate(TARGET_NAMES):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        n_jobs=2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    rf.fit(X_train, Y_train[:, i])\n",
    "    models_rf[t] = rf\n",
    "\n",
    "print(\"Trained RF models:\", list(models_rf.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7f248",
   "metadata": {
    "papermill": {
     "duration": 0.005673,
     "end_time": "2026-01-23T05:14:50.942831",
     "exception": false,
     "start_time": "2026-01-23T05:14:50.937158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Inference: Extract features once per unique test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a3de78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:14:50.956726Z",
     "iopub.status.busy": "2026-01-23T05:14:50.955856Z",
     "iopub.status.idle": "2026-01-23T05:14:52.978141Z",
     "shell.execute_reply": "2026-01-23T05:14:52.977075Z"
    },
    "papermill": {
     "duration": 2.031658,
     "end_time": "2026-01-23T05:14:52.980321",
     "exception": false,
     "start_time": "2026-01-23T05:14:50.948663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL7] Using TTA views: 3 (validation/inference-only)\n",
      "[CELL7] Extracting features for TTA view 1/3 ...\n",
      "[CELL4] extract_features: 1 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] total_batches=1\n",
      "[CELL4] First batch: (1, 3, 224, 224)\n",
      "[CELL4] Progress: 1/1\n",
      "[CELL4] features shape: (1, 512)\n",
      "[CELL7] Extracting features for TTA view 2/3 ...\n",
      "[CELL4] extract_features: 1 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] total_batches=1\n",
      "[CELL4] First batch: (1, 3, 224, 224)\n",
      "[CELL4] Progress: 1/1\n",
      "[CELL4] features shape: (1, 512)\n",
      "[CELL7] Extracting features for TTA view 3/3 ...\n",
      "[CELL4] extract_features: 1 images | batch_size=16 | workers=0\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[CELL4] total_batches=1\n",
      "[CELL4] First batch: (1, 3, 224, 224)\n",
      "[CELL4] Progress: 1/1\n",
      "[CELL4] features shape: (1, 512)\n",
      "[CELL7] Averaging predictions across TTA views ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7 — Inference (extract features once per unique test image)\n",
    "# ============================================\n",
    "needed_cols = {\"sample_id\", \"image_path\", \"target_name\"}\n",
    "if not needed_cols.issubset(test_df.columns):\n",
    "    raise ValueError(f\"test.csv must contain columns {sorted(needed_cols)}\")\n",
    "\n",
    "unique_test_paths = test_df[\"image_path\"].drop_duplicates().tolist()\n",
    "unique_test_abs = [os.path.join(DATA_DIR, p) for p in unique_test_paths]\n",
    "\n",
    "# ----------------------------\n",
    "# TTA (validation/inference-only)\n",
    "# ----------------------------\n",
    "tta_transforms = get_tta_transforms()\n",
    "print(f\"[CELL7] Using TTA views: {len(tta_transforms)} (validation/inference-only)\")\n",
    "\n",
    "# Extract features for each TTA view\n",
    "X_test_views = []\n",
    "for i, tfm in enumerate(tta_transforms):\n",
    "    print(f\"[CELL7] Extracting features for TTA view {i+1}/{len(tta_transforms)} ...\")\n",
    "    X_view = extract_features(unique_test_abs, batch_size=16, transform=tfm)\n",
    "    X_test_views.append(X_view)\n",
    "\n",
    "# Average predictions across TTA views (matches LB logic: ensemble over views)\n",
    "print(\"[CELL7] Averaging predictions across TTA views ...\")\n",
    "pred_matrix = np.zeros((len(unique_test_paths), len(TARGET_NAMES)), dtype=np.float32)\n",
    "for j, t in enumerate(TARGET_NAMES):\n",
    "    view_preds = []\n",
    "    for X_view in X_test_views:\n",
    "        view_preds.append(models_rf[t].predict(X_view))\n",
    "    pred_matrix[:, j] = np.mean(np.stack(view_preds, axis=0), axis=0).astype(np.float32)\n",
    "\n",
    "pred_wide = pd.DataFrame(pred_matrix, columns=TARGET_NAMES)\n",
    "pred_wide[\"image_path\"] = unique_test_paths\n",
    "\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=\"image_path\",\n",
    "    var_name=\"target_name\",\n",
    "    value_name=\"target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108487a",
   "metadata": {
    "papermill": {
     "duration": 0.005868,
     "end_time": "2026-01-23T05:14:52.992378",
     "exception": false,
     "start_time": "2026-01-23T05:14:52.986510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae2a1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:14:53.006299Z",
     "iopub.status.busy": "2026-01-23T05:14:53.005753Z",
     "iopub.status.idle": "2026-01-23T05:14:53.035352Z",
     "shell.execute_reply": "2026-01-23T05:14:53.034286Z"
    },
    "papermill": {
     "duration": 0.039246,
     "end_time": "2026-01-23T05:14:53.037494",
     "exception": false,
     "start_time": "2026-01-23T05:14:52.998248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing submission directly from predictions...\n",
      "Step 2: Constructing sample_id...\n",
      "✅ Submission saved to: /kaggle/working/submission.csv\n",
      "   Shape: (5, 2)\n",
      "   Unique Targets: ['Dry_Clover_g' 'Dry_Dead_g' 'Dry_Green_g' 'Dry_Total_g' 'GDM_g']\n",
      "   Head:\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   2.007529\n",
      "1    ID1001187975__Dry_Dead_g  23.641769\n",
      "2   ID1001187975__Dry_Green_g  21.688047\n",
      "3   ID1001187975__Dry_Total_g  39.692436\n",
      "4         ID1001187975__GDM_g  19.860756\n"
     ]
    }
   ],
   "source": [
    "pred_long.head()\n",
    "SUBMISSION_PATH = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "def generate_submission_direct(pred_long: pd.DataFrame, output_path: str = SUBMISSION_PATH):\n",
    "    print(\"Step 1: Preparing submission directly from predictions...\")\n",
    "    \n",
    "    # We work on a copy to avoid SettingWithCopy warnings\n",
    "    sub = pred_long.copy()\n",
    "    \n",
    "    # --- A. CLEAN THE ID ---\n",
    "    # In Cell 3 (Hijack), we set image_path = \"test/image_01.jpg\"\n",
    "    # We need just \"image_01\" for the sample_id.\n",
    "    \n",
    "    # 1. Strip directory prefix (get \"image_01.jpg\")\n",
    "    sub['filename'] = sub['image_path'].apply(lambda x: os.path.basename(str(x)))\n",
    "    \n",
    "    # 2. Strip extension (get \"image_01\")\n",
    "    sub['image_id'] = sub['filename'].apply(lambda x: os.path.splitext(x)[0])\n",
    "    \n",
    "    # --- B. CONSTRUCT SAMPLE_ID ---\n",
    "    # Logic: {ImageID}__{TargetName}\n",
    "    print(\"Step 2: Constructing sample_id...\")\n",
    "    sub['sample_id'] = sub['image_id'] + \"__\" + sub['target_name']\n",
    "    \n",
    "    # --- C. CLIP NEGATIVES ---\n",
    "    # (Incorporating the smart logic from your POC)\n",
    "    num_negatives = (sub[\"target\"] < 0).sum()\n",
    "    if num_negatives > 0:\n",
    "        print(f\"⚠️ WARNING: Found {num_negatives} negative predictions. Clipping to 0.\")\n",
    "        sub[\"target\"] = sub[\"target\"].clip(lower=0)\n",
    "        \n",
    "    # --- D. FINALIZE ---\n",
    "    # Select ONLY the required columns\n",
    "    final_output = sub[['sample_id', 'target']].copy()\n",
    "    \n",
    "    # Sort to be tidy (helps with debugging)\n",
    "    final_output = final_output.sort_values('sample_id')\n",
    "    \n",
    "    # Safety Check: Do we have NaNs?\n",
    "    if final_output['target'].isna().any():\n",
    "        print(\"❌ CRITICAL: NaNs found in target. Filling with 0.\")\n",
    "        final_output['target'] = final_output['target'].fillna(0)\n",
    "\n",
    "    # --- E. SAVE ---\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    final_output.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"✅ Submission saved to: {output_path}\")\n",
    "    print(f\"   Shape: {final_output.shape}\")\n",
    "    print(f\"   Unique Targets: {sub['target_name'].unique()}\")\n",
    "    print(\"   Head:\")\n",
    "    print(final_output.head())\n",
    "    \n",
    "    return final_output\n",
    "\n",
    "# --- EXECUTE ---\n",
    "try:\n",
    "    submission = generate_submission_direct(pred_long, SUBMISSION_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error generating submission: {e}\")\n",
    "    # Optional: If you want a crash-safe dummy fallback, add it here.\n",
    "    # But for now, it's better to see the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e27d2",
   "metadata": {
    "papermill": {
     "duration": 0.006018,
     "end_time": "2026-01-23T05:14:53.049722",
     "exception": false,
     "start_time": "2026-01-23T05:14:53.043704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. SANITY CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63cbfe6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:14:53.064378Z",
     "iopub.status.busy": "2026-01-23T05:14:53.063939Z",
     "iopub.status.idle": "2026-01-23T05:14:53.521899Z",
     "shell.execute_reply": "2026-01-23T05:14:53.520791Z"
    },
    "papermill": {
     "duration": 0.467901,
     "end_time": "2026-01-23T05:14:53.524158",
     "exception": false,
     "start_time": "2026-01-23T05:14:53.056257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "SANITY CHECKS\n",
      "====================\n",
      "[Sanity] unique_test_abs: 1\n",
      "[Sanity] subset_paths: 1 | example: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "\n",
      "[Sanity] TTA view 1/3\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[Sanity] batch.shape: (1, 3, 224, 224)\n",
      "[Sanity] batch.dtype : torch.float32\n",
      "[Sanity] batch.min/max: -2.1179039478302 2.1519827842712402\n",
      "[Sanity] feats.shape: (1, 512)\n",
      "[Sanity] feats.dtype : torch.float32\n",
      "\n",
      "[Sanity] TTA view 2/3\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[Sanity] batch.shape: (1, 3, 224, 224)\n",
      "[Sanity] batch.dtype : torch.float32\n",
      "[Sanity] batch.min/max: -2.1179039478302 2.1519827842712402\n",
      "[Sanity] feats.shape: (1, 512)\n",
      "[Sanity] feats.dtype : torch.float32\n",
      "\n",
      "[Sanity] TTA view 3/3\n",
      "[CELL4] Dataset init: 1 images\n",
      "[CELL4] Example path: /kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "[Sanity] batch.shape: (1, 3, 224, 224)\n",
      "[Sanity] batch.dtype : torch.float32\n",
      "[Sanity] batch.min/max: -2.1179039478302 2.1519827842712402\n",
      "[Sanity] feats.shape: (1, 512)\n",
      "[Sanity] feats.dtype : torch.float32\n",
      "\n",
      "✅ Sanity checks passed (no exceptions).\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks\n",
    "print(\"\\n====================\")\n",
    "print(\"SANITY CHECKS\")\n",
    "print(\"====================\")\n",
    "\n",
    "# 1) Instantiate affected dataset(s)/dataloader(s) with TTA transforms\n",
    "try:\n",
    "    tta_transforms_sc = get_tta_transforms()\n",
    "    n_imgs = len(unique_test_abs)\n",
    "    print(\"[Sanity] unique_test_abs:\", n_imgs)\n",
    "\n",
    "    if n_imgs == 0:\n",
    "        print(\"[Sanity] No test images found to validate transforms/dataloader.\")\n",
    "    else:\n",
    "        # Use a small subset for quick sanity\n",
    "        subset_paths = unique_test_abs[:min(8, n_imgs)]\n",
    "        print(\"[Sanity] subset_paths:\", len(subset_paths), \"| example:\", subset_paths[0])\n",
    "\n",
    "        for v_idx, tfm in enumerate(tta_transforms_sc):\n",
    "            print(f\"\\n[Sanity] TTA view {v_idx+1}/{len(tta_transforms_sc)}\")\n",
    "\n",
    "            ds_sc = ImagePathDataset(subset_paths, transform=tfm)\n",
    "            dl_sc = DataLoader(\n",
    "                ds_sc,\n",
    "                batch_size=min(4, len(ds_sc)),\n",
    "                shuffle=False,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                pin_memory=(DEVICE == \"cuda\"),\n",
    "            )\n",
    "\n",
    "            batch = next(iter(dl_sc))\n",
    "            print(\"[Sanity] batch.shape:\", tuple(batch.shape))\n",
    "            print(\"[Sanity] batch.dtype :\", batch.dtype)\n",
    "            print(\"[Sanity] batch.min/max:\", float(batch.min()), float(batch.max()))\n",
    "\n",
    "            # 2) Run one batch through extractor\n",
    "            with torch.no_grad():\n",
    "                batch_dev = batch.to(DEVICE, non_blocking=True)\n",
    "                feats = EXTRACTOR(batch_dev).view(batch_dev.size(0), -1)\n",
    "            print(\"[Sanity] feats.shape:\", tuple(feats.shape))\n",
    "            print(\"[Sanity] feats.dtype :\", feats.dtype)\n",
    "\n",
    "        print(\"\\n✅ Sanity checks passed (no exceptions).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n❌ Sanity checks failed with exception:\")\n",
    "    print(type(e).__name__, str(e))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b3839",
   "metadata": {
    "papermill": {
     "duration": 0.006497,
     "end_time": "2026-01-23T05:14:53.538239",
     "exception": false,
     "start_time": "2026-01-23T05:14:53.531742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. EXPORT AUGMENTED IMAGES SO THAT CHU NHAT CAN FIND BEST PARAMETERS FOR RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9b4b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:14:53.553179Z",
     "iopub.status.busy": "2026-01-23T05:14:53.552810Z",
     "iopub.status.idle": "2026-01-23T05:15:46.371774Z",
     "shell.execute_reply": "2026-01-23T05:15:46.370721Z"
    },
    "papermill": {
     "duration": 52.834872,
     "end_time": "2026-01-23T05:15:46.379380",
     "exception": false,
     "start_time": "2026-01-23T05:14:53.544508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Export] Using TRAIN images: 357\n",
      "[Export] Writing augmented TRAIN images to: /kaggle/working/augmented_train_images\n",
      "[Export] 1/357 done\n",
      "[Export] 200/357 done\n",
      "[Export] 357/357 done\n",
      "[Export] Completed. Success=357, Failed=0\n",
      "[Export] Output folder: /kaggle/working/augmented_train_images\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Export augmented TRAIN images only (original / hflip / vflip)\n",
    "# Writes to: /kaggle/working/augmented_train_images/{original,hflip,vflip}/\n",
    "# ============================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# ---- Config ----\n",
    "OUTPUT_DIR = Path(\"/kaggle/working/augmented_train_images\")\n",
    "MAX_IMAGES = None  # set to an int (e.g., 500) to limit exports; None = export all\n",
    "\n",
    "# ---- Force training image source ----\n",
    "if \"train_wide\" in globals() and \"abs_path\" in train_wide.columns and len(train_wide) > 0:\n",
    "    export_abs_paths = train_wide[\"abs_path\"].tolist()\n",
    "    export_rel_paths = train_wide[\"image_path\"].tolist()\n",
    "    print(f\"[Export] Using TRAIN images: {len(export_abs_paths)}\")\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        \"train_wide['abs_path'] not found. Run the cell that builds train_wide and its abs_path first.\"\n",
    "    )\n",
    "\n",
    "# Apply MAX_IMAGES cap (optional)\n",
    "if isinstance(MAX_IMAGES, int) and MAX_IMAGES > 0:\n",
    "    export_abs_paths = export_abs_paths[:MAX_IMAGES]\n",
    "    export_rel_paths = export_rel_paths[:MAX_IMAGES]\n",
    "    print(f\"[Export] Capped to MAX_IMAGES={MAX_IMAGES}\")\n",
    "\n",
    "# ---- Save-friendly augmentation pipelines (PIL outputs; NO Normalize/ToTensor) ----\n",
    "# Geometric intent matches get_tta_transforms(): original / hflip / vflip\n",
    "save_views = {\n",
    "    \"original\": transforms.Compose([\n",
    "        SquarePad(),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "    \"hflip\": transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        SquarePad(),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "    \"vflip\": transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(p=1.0),\n",
    "        SquarePad(),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# ---- Create output folders ----\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "for view_name in save_views.keys():\n",
    "    (OUTPUT_DIR / view_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[Export] Writing augmented TRAIN images to: {OUTPUT_DIR}\")\n",
    "\n",
    "# ---- Export loop ----\n",
    "n_ok, n_fail = 0, 0\n",
    "for i, (abs_p, rel_p) in enumerate(zip(export_abs_paths, export_rel_paths), start=1):\n",
    "    try:\n",
    "        img = Image.open(abs_p).convert(\"RGB\")\n",
    "        base_name = Path(rel_p).name  # keep original filename\n",
    "        stem = Path(base_name).stem\n",
    "        ext = \".jpg\"  # write as jpg for consistent output size\n",
    "\n",
    "        for view_name, tfm in save_views.items():\n",
    "            out_img = tfm(img)  # PIL image\n",
    "            out_path = OUTPUT_DIR / view_name / f\"{stem}__{view_name}{ext}\"\n",
    "            out_img.save(out_path, quality=95)\n",
    "\n",
    "        n_ok += 1\n",
    "        if i == 1 or i % 200 == 0 or i == len(export_abs_paths):\n",
    "            print(f\"[Export] {i}/{len(export_abs_paths)} done\")\n",
    "\n",
    "    except Exception as e:\n",
    "        n_fail += 1\n",
    "        if n_fail <= 10:\n",
    "            print(f\"[Export][WARN] Failed on: {abs_p} | {type(e).__name__}: {e}\")\n",
    "\n",
    "print(f\"[Export] Completed. Success={n_ok}, Failed={n_fail}\")\n",
    "print(f\"[Export] Output folder: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457c24e",
   "metadata": {
    "papermill": {
     "duration": 0.006992,
     "end_time": "2026-01-23T05:15:46.392812",
     "exception": false,
     "start_time": "2026-01-23T05:15:46.385820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11 DOWNLOAD OUTPUT AUGMENTED IMAGES BY USING SHUTIL LIBRARY IN PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f3a336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:15:46.408529Z",
     "iopub.status.busy": "2026-01-23T05:15:46.407514Z",
     "iopub.status.idle": "2026-01-23T05:15:47.422167Z",
     "shell.execute_reply": "2026-01-23T05:15:47.421034Z"
    },
    "papermill": {
     "duration": 1.025088,
     "end_time": "2026-01-23T05:15:47.424435",
     "exception": false,
     "start_time": "2026-01-23T05:15:46.399347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archived /kaggle/working/augmented_train_images to augmented_train_images_archive.zip\n",
      "✅ Zip saved at: /kaggle/working/augmented_train_images_archive.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the directory you want to zip (the augmented TRAIN images folder we created)\n",
    "directory_to_zip = '/kaggle/working/augmented_train_images'\n",
    "\n",
    "# Define the output filename (without extension)\n",
    "output_filename = 'augmented_train_images_archive'\n",
    "\n",
    "# Create the zip archive\n",
    "shutil.make_archive(output_filename, 'zip', directory_to_zip)\n",
    "\n",
    "print(f\"Archived {directory_to_zip} to {output_filename}.zip\")\n",
    "print(\"✅ Zip saved at:\", os.path.join(\"/kaggle/working\", f\"{output_filename}.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fabdd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:15:47.440388Z",
     "iopub.status.busy": "2026-01-23T05:15:47.439476Z",
     "iopub.status.idle": "2026-01-23T05:15:47.473564Z",
     "shell.execute_reply": "2026-01-23T05:15:47.472420Z"
    },
    "papermill": {
     "duration": 0.044942,
     "end_time": "2026-01-23T05:15:47.475954",
     "exception": false,
     "start_time": "2026-01-23T05:15:47.431012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images folder: /kaggle/working/augmented_train_images\n",
      "Counts by view:\n",
      "  - original: 357\n",
      "  - hflip: 357\n",
      "  - vflip: 357\n",
      "TOTAL exported images: 1071\n",
      "Unique base images represented: 357\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Count how many images were exported in /kaggle/working/augmented_train_images\n",
    "# (overall + per subfolder)\n",
    "# ============================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "AUG_DIR = Path(\"/kaggle/working/augmented_train_images\")\n",
    "if not AUG_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Folder not found: {AUG_DIR}\")\n",
    "\n",
    "valid_ext = {\".jpg\", \".jpeg\", \".png\"}\n",
    "\n",
    "counts = {}\n",
    "total = 0\n",
    "\n",
    "for view in [\"original\", \"hflip\", \"vflip\"]:\n",
    "    view_dir = AUG_DIR / view\n",
    "    if not view_dir.exists():\n",
    "        counts[view] = 0\n",
    "        continue\n",
    "    n = sum(1 for p in view_dir.iterdir() if p.is_file() and p.suffix.lower() in valid_ext)\n",
    "    counts[view] = n\n",
    "    total += n\n",
    "\n",
    "print(\"Augmented images folder:\", str(AUG_DIR))\n",
    "print(\"Counts by view:\")\n",
    "for k, v in counts.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "print(\"TOTAL exported images:\", total)\n",
    "\n",
    "# Optional: count unique base stems (original image IDs) if you used naming stem__view.jpg\n",
    "unique_stems = set()\n",
    "for view in [\"original\", \"hflip\", \"vflip\"]:\n",
    "    view_dir = AUG_DIR / view\n",
    "    if not view_dir.exists():\n",
    "        continue\n",
    "    for p in view_dir.iterdir():\n",
    "        if p.is_file() and p.suffix.lower() in valid_ext:\n",
    "            name = p.stem  # e.g., \"abc__hflip\"\n",
    "            base = name.split(\"__\")[0] if \"__\" in name else name\n",
    "            unique_stems.add(base)\n",
    "\n",
    "print(\"Unique base images represented:\", len(unique_stems))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 2847,
     "sourceId": 4958,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 281.70918,
   "end_time": "2026-01-23T05:15:49.901882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-23T05:11:08.192702",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
